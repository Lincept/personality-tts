"""
Phase 2.2 - SlangDecoderAgent å•å…ƒæµ‹è¯•

æµ‹è¯•é»‘è¯è§£ç æ™ºèƒ½ä½“çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åˆå§‹åŒ–å’Œè¯å…¸åŠ è½½
2. é»‘è¯è¯†åˆ«å’Œè§£ç 
3. è¯å…¸åŠ¨æ€æ›´æ–°
4. æ‰¹é‡å¤„ç†
5. è¯å…¸æŒä¹…åŒ–
6. æœç´¢å’Œç»Ÿè®¡åŠŸèƒ½

ä½œè€…ï¼šAI Data Factory
åˆ›å»ºæ—¥æœŸï¼š2026-01-19
"""

import sys
import os
from pathlib import Path
import json
import tempfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agents.slang_decoder import SlangDecoderAgent
from models.schemas import SlangDecodingResult


class MockLLMProvider:
    """Mock LLM Provider for testing"""
    
    def generate_structured(self, messages, response_model=None, **kwargs):
        """æ¨¡æ‹Ÿ LLM çš„ç»“æ„åŒ–è¾“å‡º"""
        # response_model å‚æ•°è®¾ä¸ºå¯é€‰ï¼Œé»˜è®¤ä¸º SlangDecodingResult
        if response_model is None:
            response_model = SlangDecodingResult
        
        # ä» messages ä¸­æå–ç”¨æˆ·è¾“å…¥
        user_message = None
        for msg in messages:
            if msg.get("role") == "user":
                user_message = msg.get("content", "")
                break
        
        # æ¨¡æ‹Ÿé»‘è¯è¯†åˆ«é€»è¾‘
        text = user_message if user_message else ""
        
        slang_patterns = {
            "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
            "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°",
            "å­¦æœ¯é»‘å‚": "å·¥ä½œç¯å¢ƒæ¶åŠ£ã€å‹æ¦¨å­¦ç”Ÿçš„å®éªŒå®¤",
            "é¸½å­ç‹": "ç»å¸¸çˆ½çº¦ã€ä¸å®ˆä¿¡ç”¨çš„äºº",
            "PPTå¹å¾—å¤©èŠ±ä¹±å ": "å®£ä¼ æ—¶å¤¸å¤§å…¶è¯",
            "æ”¾å…»": "å¯¼å¸ˆå¾ˆå°‘æŒ‡å¯¼å­¦ç”Ÿ",
            "å†…å·": "è¿‡åº¦ç«äº‰å¯¼è‡´æ•ˆç‡ä½ä¸‹"
        }
        
        # è¯†åˆ«æ–‡æœ¬ä¸­çš„é»‘è¯
        identified_slang = {}
        decoded_text = text
        
        for slang, meaning in slang_patterns.items():
            if slang in text:
                identified_slang[slang] = meaning
                decoded_text = decoded_text.replace(slang, meaning)
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°é»‘è¯ï¼Œè¿”å›åŸæ–‡
        if not identified_slang:
            decoded_text = text
            confidence = 0.6
        else:
            confidence = 0.9
        
        return SlangDecodingResult(
            decoded_text=decoded_text,
            slang_dictionary=identified_slang,
            confidence_score=confidence,
            success=True
        )


def test_initialization():
    """æµ‹è¯•1ï¼šåˆå§‹åŒ–å’Œè¯å…¸åŠ è½½"""
    print("\n" + "="*70)
    print("æµ‹è¯•1ï¼šSlangDecoderAgent åˆå§‹åŒ–")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    
    # æ— è¯å…¸åˆå§‹åŒ–
    decoder = SlangDecoderAgent(llm_provider)
    assert len(decoder.slang_dictionary) == 0
    print("âœ“ æ— è¯å…¸åˆå§‹åŒ–æˆåŠŸ")
    
    # ä½¿ç”¨ä¸´æ—¶è¯å…¸æ–‡ä»¶åˆå§‹åŒ–
    with tempfile.NamedTemporaryFile(
        mode='w',
        suffix='.json',
        delete=False,
        encoding='utf-8'
    ) as f:
        initial_dict = {
            "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
            "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°"
        }
        json.dump(initial_dict, f, ensure_ascii=False)
        temp_path = Path(f.name)
    
    try:
        decoder_with_dict = SlangDecoderAgent(
            llm_provider,
            slang_dict_path=temp_path
        )
        assert len(decoder_with_dict.slang_dictionary) == 2
        assert "å­¦æœ¯å¦²å·±" in decoder_with_dict.slang_dictionary
        print(f"âœ“ ä»æ–‡ä»¶åŠ è½½è¯å…¸æˆåŠŸ ({len(decoder_with_dict.slang_dictionary)} ä¸ªæœ¯è¯­)")
    finally:
        temp_path.unlink()
    
    print("âœ… æµ‹è¯•1é€šè¿‡ï¼")
    return True


def test_decode_slang():
    """æµ‹è¯•2ï¼šé»‘è¯è¯†åˆ«å’Œè§£ç """
    print("\n" + "="*70)
    print("æµ‹è¯•2ï¼šé»‘è¯è¯†åˆ«å’Œè§£ç ")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    # åœºæ™¯1ï¼šåŒ…å«å¤šä¸ªé»‘è¯çš„æ–‡æœ¬
    text1 = "è¿™ä¸ªå¯¼å¸ˆæ˜¯å­¦æœ¯å¦²å·±ï¼Œæ€»æ˜¯ç”»é¥¼ï¼Œå®éªŒå®¤å°±æ˜¯å­¦æœ¯é»‘å‚"
    result1 = decoder.process(text1)
    
    print(f"\nè¾“å…¥æ–‡æœ¬: {text1}")
    print(f"è§£ç ç»“æœ: {result1.decoded_text}")
    print(f"è¯†åˆ«é»‘è¯: {list(result1.slang_dictionary.keys())}")
    print(f"ç½®ä¿¡åº¦: {result1.confidence_score}")
    
    assert result1.success
    assert len(result1.slang_dictionary) > 0
    assert result1.decoded_text != text1  # åº”è¯¥æœ‰å˜åŒ–
    print("âœ“ åœºæ™¯1ï¼šå¤šé»‘è¯æ–‡æœ¬è§£ç æˆåŠŸ")
    
    # åœºæ™¯2ï¼šæ— é»‘è¯çš„æ™®é€šæ–‡æœ¬
    text2 = "å¯¼å¸ˆå¾ˆå¥½ï¼Œç»è´¹å……è¶³ï¼ŒæŒ‡å¯¼è®¤çœŸ"
    result2 = decoder.process(text2)
    
    print(f"\nè¾“å…¥æ–‡æœ¬: {text2}")
    print(f"è§£ç ç»“æœ: {result2.decoded_text}")
    print(f"è¯†åˆ«é»‘è¯: {list(result2.slang_dictionary.keys())}")
    
    assert result2.success
    print("âœ“ åœºæ™¯2ï¼šæ™®é€šæ–‡æœ¬å¤„ç†æˆåŠŸ")
    
    print("âœ… æµ‹è¯•2é€šè¿‡ï¼")
    return True


def test_update_dictionary():
    """æµ‹è¯•3ï¼šè¯å…¸åŠ¨æ€æ›´æ–°"""
    print("\n" + "="*70)
    print("æµ‹è¯•3ï¼šè¯å…¸åŠ¨æ€æ›´æ–°")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    initial_count = len(decoder.slang_dictionary)
    print(f"åˆå§‹è¯å…¸å¤§å°: {initial_count}")
    
    # æ·»åŠ æ–°æœ¯è¯­
    new_terms = {
        "é¸½å­ç‹": "ç»å¸¸çˆ½çº¦ã€ä¸å®ˆä¿¡ç”¨çš„äºº",
        "æ”¾å…»": "å¯¼å¸ˆå¾ˆå°‘æŒ‡å¯¼å­¦ç”Ÿ"
    }
    
    updated_count = decoder.update_dictionary(new_terms)
    print(f"æ›´æ–°äº† {updated_count} ä¸ªæœ¯è¯­")
    print(f"å½“å‰è¯å…¸å¤§å°: {len(decoder.slang_dictionary)}")
    
    assert len(decoder.slang_dictionary) >= initial_count + 2
    assert "é¸½å­ç‹" in decoder.slang_dictionary
    assert "æ”¾å…»" in decoder.slang_dictionary
    print("âœ“ è¯å…¸æ›´æ–°æˆåŠŸ")
    
    # æ›´æ–°å·²æœ‰æœ¯è¯­
    override_terms = {"é¸½å­ç‹": "ç»å¸¸ä¸å®ˆçº¦å®šçš„å¯¼å¸ˆ"}
    decoder.update_dictionary(override_terms)
    assert decoder.slang_dictionary["é¸½å­ç‹"] == "ç»å¸¸ä¸å®ˆçº¦å®šçš„å¯¼å¸ˆ"
    print("âœ“ æœ¯è¯­è¦†ç›–æ›´æ–°æˆåŠŸ")
    
    print("âœ… æµ‹è¯•3é€šè¿‡ï¼")
    return True


def test_validate_output():
    """æµ‹è¯•4ï¼šè¾“å‡ºéªŒè¯"""
    print("\n" + "="*70)
    print("æµ‹è¯•4ï¼šè¾“å‡ºéªŒè¯")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    # æœ‰æ•ˆè¾“å‡º
    valid_output = SlangDecodingResult(
        decoded_text="å¯¼å¸ˆå–„äºæ‰¿è¯ºä½†ä¸å…‘ç°",
        slang_dictionary={"å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ"},
        confidence_score=0.9
    )
    assert decoder.validate_output(valid_output) is True
    print("âœ“ æœ‰æ•ˆè¾“å‡ºéªŒè¯é€šè¿‡")
    
    # ç©ºæ–‡æœ¬
    invalid_output = SlangDecodingResult(
        decoded_text="",
        slang_dictionary={},
        confidence_score=0.5
    )
    assert decoder.validate_output(invalid_output) is False
    print("âœ“ ç©ºæ–‡æœ¬æ­£ç¡®æ‹’ç»")
    
    # æ— æ•ˆç½®ä¿¡åº¦
    try:
        invalid_confidence = SlangDecodingResult(
            decoded_text="æµ‹è¯•",
            slang_dictionary={},
            confidence_score=1.5
        )
        print("âŒ åº”è¯¥æ‹’ç»æ— æ•ˆç½®ä¿¡åº¦")
        return False
    except Exception:
        print("âœ“ æ— æ•ˆç½®ä¿¡åº¦æ­£ç¡®æ‹’ç»")
    
    print("âœ… æµ‹è¯•4é€šè¿‡ï¼")
    return True


def test_batch_decode():
    """æµ‹è¯•5ï¼šæ‰¹é‡è§£ç """
    print("\n" + "="*70)
    print("æµ‹è¯•5ï¼šæ‰¹é‡è§£ç ")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    texts = [
        "è¿™ä¸ªå¯¼å¸ˆæ˜¯å­¦æœ¯å¦²å·±",
        "å®éªŒå®¤å†…å·ä¸¥é‡",
        "å¯¼å¸ˆç»å¸¸æ”¾å…»å­¦ç”Ÿ",
        "ç»è´¹å……è¶³ï¼Œç¯å¢ƒè‰¯å¥½"
    ]
    
    results = decoder.decode_batch(texts)
    
    print(f"æ‰¹é‡å¤„ç† {len(texts)} æ¡æ–‡æœ¬")
    print(f"æˆåŠŸå¤„ç†: {sum(1 for r in results if r.success)}/{len(results)}")
    
    for i, result in enumerate(results, 1):
        status = "âœ…" if result.success else "âŒ"
        slang_count = len(result.slang_dictionary)
        print(f"  {status} æ–‡æœ¬{i}: è¯†åˆ« {slang_count} ä¸ªé»‘è¯")
    
    assert len(results) == len(texts)
    assert all(r.success for r in results)
    
    print("âœ… æµ‹è¯•5é€šè¿‡ï¼")
    return True


def test_dictionary_persistence():
    """æµ‹è¯•6ï¼šè¯å…¸æŒä¹…åŒ–"""
    print("\n" + "="*70)
    print("æµ‹è¯•6ï¼šè¯å…¸æŒä¹…åŒ–")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_file = Path(tempfile.gettempdir()) / "test_slang_dict.json"
    
    try:
        # ç¬¬ä¸€ä¸ªå®ä¾‹ï¼šåˆ›å»ºå¹¶ä¿å­˜è¯å…¸
        decoder1 = SlangDecoderAgent(
            llm_provider,
            slang_dict_path=temp_file,
            auto_save=True
        )
        
        decoder1.update_dictionary({
            "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
            "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°"
        })
        
        dict_size_1 = len(decoder1.slang_dictionary)
        print(f"âœ“ ç¬¬ä¸€ä¸ªå®ä¾‹ä¿å­˜è¯å…¸: {dict_size_1} ä¸ªæœ¯è¯­")
        
        # ç¬¬äºŒä¸ªå®ä¾‹ï¼šåŠ è½½ä¿å­˜çš„è¯å…¸
        decoder2 = SlangDecoderAgent(
            llm_provider,
            slang_dict_path=temp_file
        )
        
        dict_size_2 = len(decoder2.slang_dictionary)
        print(f"âœ“ ç¬¬äºŒä¸ªå®ä¾‹åŠ è½½è¯å…¸: {dict_size_2} ä¸ªæœ¯è¯­")
        
        assert dict_size_1 == dict_size_2
        assert decoder2.slang_dictionary == decoder1.slang_dictionary
        print("âœ“ è¯å…¸æŒä¹…åŒ–æˆåŠŸ")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file.exists():
            temp_file.unlink()
    
    print("âœ… æµ‹è¯•6é€šè¿‡ï¼")
    return True


def test_search_and_stats():
    """æµ‹è¯•7ï¼šæœç´¢å’Œç»Ÿè®¡åŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯•7ï¼šæœç´¢å’Œç»Ÿè®¡åŠŸèƒ½")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    # æ·»åŠ æµ‹è¯•æ•°æ®
    decoder.update_dictionary({
        "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
        "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°",
        "å­¦æœ¯é»‘å‚": "å·¥ä½œç¯å¢ƒæ¶åŠ£çš„å®éªŒå®¤",
        "æ”¾å…»": "å¯¼å¸ˆå¾ˆå°‘æŒ‡å¯¼"
    })
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = decoder.get_dictionary_stats()
    print(f"\nè¯å…¸ç»Ÿè®¡:")
    print(f"  - æ€»æœ¯è¯­æ•°: {stats['total_terms']}")
    print(f"  - è‡ªåŠ¨ä¿å­˜: {stats['auto_save_enabled']}")
    print(f"  - ç¤ºä¾‹æœ¯è¯­: {list(stats['sample_terms'].keys())}")
    
    assert stats['total_terms'] == 4
    print("âœ“ ç»Ÿè®¡ä¿¡æ¯æ­£ç¡®")
    
    # æœç´¢åŠŸèƒ½
    search_results = decoder.search_slang("å­¦æœ¯")
    print(f"\næœç´¢ 'å­¦æœ¯' çš„ç»“æœ: {len(search_results)} æ¡")
    for slang, meaning in search_results.items():
        print(f"  - {slang}: {meaning}")
    
    assert len(search_results) >= 2  # "å­¦æœ¯å¦²å·±" å’Œ "å­¦æœ¯é»‘å‚"
    print("âœ“ æœç´¢åŠŸèƒ½æ­£å¸¸")
    
    print("âœ… æµ‹è¯•7é€šè¿‡ï¼")
    return True


def test_prepare_input():
    """æµ‹è¯•8ï¼šè¾“å…¥æ•°æ®å‡†å¤‡"""
    print("\n" + "="*70)
    print("æµ‹è¯•8ï¼šè¾“å…¥æ•°æ®å‡†å¤‡")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    # æ·»åŠ ä¸€äº›å·²çŸ¥é»‘è¯
    decoder.update_dictionary({
        "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
        "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°"
    })
    
    # å‡†å¤‡è¾“å…¥
    raw_text = "è¿™ä¸ªå¯¼å¸ˆæ€»æ˜¯ç”»é¥¼"
    prepared = decoder.prepare_input(raw_text)
    
    print(f"åŸå§‹è¾“å…¥: {raw_text}")
    print(f"å‡†å¤‡åçš„æ•°æ®é”®: {list(prepared.keys())}")
    print(f"è¯å…¸å¤§å°: {prepared['dictionary_size']}")
    
    assert "text" in prepared
    assert "existing_dictionary" in prepared
    assert "dictionary_size" in prepared
    assert prepared["dictionary_size"] == 2
    
    print("âœ“ è¾“å…¥æ•°æ®å‡†å¤‡æ­£ç¡®")
    print("âœ… æµ‹è¯•8é€šè¿‡ï¼")
    return True


def test_clear_dictionary():
    """æµ‹è¯•9ï¼šæ¸…ç©ºè¯å…¸"""
    print("\n" + "="*70)
    print("æµ‹è¯•9ï¼šæ¸…ç©ºè¯å…¸")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    decoder = SlangDecoderAgent(llm_provider, auto_save=False)
    
    # æ·»åŠ æ•°æ®
    decoder.update_dictionary({
        "å­¦æœ¯å¦²å·±": "å–„äºæ‰¿è¯ºä½†ä¸å…‘ç°çš„å¯¼å¸ˆ",
        "ç”»é¥¼": "åšå‡ºæ‰¿è¯ºä½†ä¸å®ç°"
    })
    
    print(f"æ¸…ç©ºå‰: {len(decoder.slang_dictionary)} ä¸ªæœ¯è¯­")
    
    # æ¸…ç©º
    decoder.clear_dictionary()
    
    print(f"æ¸…ç©ºå: {len(decoder.slang_dictionary)} ä¸ªæœ¯è¯­")
    
    assert len(decoder.slang_dictionary) == 0
    print("âœ“ è¯å…¸æ¸…ç©ºæˆåŠŸ")
    
    print("âœ… æµ‹è¯•9é€šè¿‡ï¼")
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*70)
    print("Phase 2.2 - SlangDecoderAgent å•å…ƒæµ‹è¯•")
    print("="*70)
    
    tests = [
        test_initialization,
        test_decode_slang,
        test_update_dictionary,
        test_validate_output,
        test_batch_decode,
        test_dictionary_persistence,
        test_search_and_stats,
        test_prepare_input,
        test_clear_dictionary
    ]
    
    passed = 0
    failed = 0
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
        except AssertionError as e:
            failed += 1
            print(f"âŒ æµ‹è¯•å¤±è´¥: {test_func.__name__}")
            print(f"   é”™è¯¯: {e}")
        except Exception as e:
            failed += 1
            print(f"âŒ æµ‹è¯•å¤±è´¥: {test_func.__name__}")
            print(f"   é”™è¯¯:")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)
    print(f"âœ… é€šè¿‡: {passed}/{len(tests)}")
    print(f"âŒ å¤±è´¥: {failed}/{len(tests)}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Phase 2.2 SlangDecoderAgent å®ç°æˆåŠŸï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")


if __name__ == "__main__":
    run_all_tests()
