"""
CriticAgent å•å…ƒæµ‹è¯• - Phase 2.1
æµ‹è¯•åˆ¤åˆ«èŠ‚ç‚¹æ™ºèƒ½ä½“çš„åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from datetime import datetime
from pydantic import BaseModel, Field
from typing import Dict, Any

# ç›´æ¥å¯¼å…¥ï¼Œé¿å…é€šè¿‡ __init__.py
from models.schemas import CriticFeedback, CommentCleaningResult
from agents.critic import CriticAgent


# ==================== Mock LLM Provider ====================

class MockLLMProvider:
    """æ¨¡æ‹Ÿçš„ LLM æä¾›è€…ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self, model_name: str = "mock-model"):
        self.model_name = model_name
        self.call_count = 0
    
    def generate_structured(
        self,
        messages: list,
        response_format: type,
        **kwargs
    ):
        """æ¨¡æ‹Ÿç»“æ„åŒ–ç”Ÿæˆ"""
        self.call_count += 1
        
        # è§£ææ¶ˆæ¯ï¼Œåˆ¤æ–­åº”è¯¥è¿”å›é€šè¿‡è¿˜æ˜¯ä¸é€šè¿‡
        user_message = next(
            (m['content'] for m in messages if m['role'] == 'user'),
            ""
        )
        
        # ç®€å•çš„è§„åˆ™ï¼šå¦‚æœè¾“å‡ºä¸­åŒ…å« "é«˜è´¨é‡" æˆ– quality_score > 0.7ï¼Œåˆ™é€šè¿‡
        if "é«˜è´¨é‡" in user_message or '"quality_score": 0.8' in user_message:
            return CriticFeedback(
                is_approved=True,
                reasoning="è¾“å‡ºè´¨é‡è‰¯å¥½ï¼Œäº‹å®å‡†ç¡®ï¼Œä¿¡æ¯å®Œæ•´",
                suggestion="",
                confidence_score=0.9
            )
        else:
            return CriticFeedback(
                is_approved=False,
                reasoning="è¾“å‡ºè´¨é‡ä¸è¶³ï¼Œä¿¡æ¯ä¸å¤Ÿå®Œæ•´æˆ–å‡†ç¡®",
                suggestion="å»ºè®®è¡¥å……æ›´å¤šç»†èŠ‚ï¼Œç¡®ä¿äº‹å®å‡†ç¡®æ€§",
                confidence_score=0.85
            )


# ==================== æµ‹è¯•ç”¨æ•°æ®æ¨¡å‹ ====================

class MockAgentOutput(BaseModel):
    """æ¨¡æ‹Ÿ Agent è¾“å‡º"""
    content: str = Field(..., description="è¾“å‡ºå†…å®¹")
    quality_score: float = Field(default=0.5, description="è´¨é‡è¯„åˆ†")
    metadata: Dict[str, Any] = Field(default_factory=dict)


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_critic_initialization():
    """æµ‹è¯•1ï¼šCriticAgent åˆå§‹åŒ–"""
    print("\n" + "="*70)
    print("æµ‹è¯•1ï¼šCriticAgent åˆå§‹åŒ–")
    print("="*70)
    
    # åˆ›å»º Mock LLM Provider
    llm_provider = MockLLMProvider()
    
    # æµ‹è¯•é»˜è®¤å‚æ•°
    critic = CriticAgent(llm_provider)
    assert critic.strictness_level == 0.7
    print("âœ“ é»˜è®¤ä¸¥æ ¼åº¦: 0.7")
    
    # æµ‹è¯•è‡ªå®šä¹‰å‚æ•°
    critic_strict = CriticAgent(llm_provider, strictness_level=0.9)
    assert critic_strict.strictness_level == 0.9
    print("âœ“ è‡ªå®šä¹‰ä¸¥æ ¼åº¦: 0.9")
    
    # æµ‹è¯•æ— æ•ˆå‚æ•°
    try:
        CriticAgent(llm_provider, strictness_level=1.5)
        assert False, "åº”è¯¥æŠ›å‡º ValueError"
    except ValueError:
        print("âœ“ æ— æ•ˆå‚æ•°æ£€æŸ¥æ­£å¸¸")
    
    print("âœ… æµ‹è¯•1é€šè¿‡ï¼")
    return True


def test_prepare_input():
    """æµ‹è¯•2ï¼šè¾“å…¥æ•°æ®å‡†å¤‡"""
    print("\n" + "="*70)
    print("æµ‹è¯•2ï¼šè¾“å…¥æ•°æ®å‡†å¤‡")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider, strictness_level=0.7)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    agent_output = MockAgentOutput(
        content="æµ‹è¯•è¾“å‡º",
        quality_score=0.8
    )
    original_input = "åŸå§‹è¾“å…¥æ–‡æœ¬"
    
    # æµ‹è¯•å‡†å¤‡è¾“å…¥
    prepared = critic.prepare_input(
        raw_input={"agent_output": agent_output, "original_input": original_input}
    )
    
    assert "agent_output" in prepared
    assert "original_input" in prepared
    assert "strictness_level" in prepared
    assert prepared["strictness_level"] == 0.7
    print(f"âœ“ è¾“å…¥æ•°æ®å‡†å¤‡æˆåŠŸ")
    print(f"  - agent_output é”®: {list(prepared['agent_output'].keys())}")
    print(f"  - strictness_level: {prepared['strictness_level']}")
    
    print("âœ… æµ‹è¯•2é€šè¿‡ï¼")
    return True


def test_strictness_descriptions():
    """æµ‹è¯•3ï¼šä¸¥æ ¼åº¦æè¿°"""
    print("\n" + "="*70)
    print("æµ‹è¯•3ï¼šä¸¥æ ¼åº¦æè¿°")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider)
    
    # æµ‹è¯•ä¸åŒä¸¥æ ¼åº¦çš„æè¿°
    desc_loose = critic._get_strictness_description(0.3)
    desc_standard = critic._get_strictness_description(0.7)
    desc_strict = critic._get_strictness_description(0.95)
    
    print(f"âœ“ å®½æ¾ (0.3): {desc_loose}")
    print(f"âœ“ æ ‡å‡† (0.7): {desc_standard}")
    print(f"âœ“ ä¸¥æ ¼ (0.95): {desc_strict}")
    
    assert "å®½æ¾" in desc_loose
    assert "æ ‡å‡†" in desc_standard
    assert "ä¸¥æ ¼" in desc_strict
    
    print("âœ… æµ‹è¯•3é€šè¿‡ï¼")
    return True


def test_evaluate_method():
    """æµ‹è¯•4ï¼ševaluate æ–¹æ³•"""
    print("\n" + "="*70)
    print("æµ‹è¯•4ï¼ševaluate æ–¹æ³•")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider, strictness_level=0.7)
    
    # æµ‹è¯•åœºæ™¯1ï¼šé«˜è´¨é‡è¾“å‡º
    print("\nåœºæ™¯1ï¼šè¯„ä¼°é«˜è´¨é‡è¾“å‡º")
    high_quality_output = MockAgentOutput(
        content="é«˜è´¨é‡è¾“å‡ºå†…å®¹",
        quality_score=0.8
    )
    
    feedback1 = critic.evaluate(
        agent_output=high_quality_output,
        original_input="åŸå§‹è¾“å…¥"
    )
    
    print(f"  - æ˜¯å¦é€šè¿‡: {feedback1.is_approved}")
    print(f"  - è¯„ä¼°ç†ç”±: {feedback1.reasoning}")
    print(f"  - ç½®ä¿¡åº¦: {feedback1.confidence_score}")
    assert feedback1.is_approved is True
    
    # æµ‹è¯•åœºæ™¯2ï¼šä½è´¨é‡è¾“å‡º
    print("\nåœºæ™¯2ï¼šè¯„ä¼°ä½è´¨é‡è¾“å‡º")
    low_quality_output = MockAgentOutput(
        content="ä½è´¨é‡è¾“å‡º",
        quality_score=0.3
    )
    
    feedback2 = critic.evaluate(
        agent_output=low_quality_output,
        original_input="åŸå§‹è¾“å…¥"
    )
    
    print(f"  - æ˜¯å¦é€šè¿‡: {feedback2.is_approved}")
    print(f"  - è¯„ä¼°ç†ç”±: {feedback2.reasoning}")
    print(f"  - æ”¹è¿›å»ºè®®: {feedback2.suggestion}")
    assert feedback2.is_approved is False
    
    print("âœ… æµ‹è¯•4é€šè¿‡ï¼")
    return True


def test_validate_output():
    """æµ‹è¯•5ï¼šè¾“å‡ºéªŒè¯"""
    print("\n" + "="*70)
    print("æµ‹è¯•5ï¼šè¾“å‡ºéªŒè¯")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider)
    
    # æœ‰æ•ˆçš„åé¦ˆ
    valid_feedback = CriticFeedback(
        is_approved=True,
        reasoning="è¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è¯„ä¼°ç†ç”±",
        confidence_score=0.9
    )
    assert critic.validate_output(valid_feedback) is True
    print("âœ“ æœ‰æ•ˆåé¦ˆéªŒè¯é€šè¿‡")
    
    # æ— æ•ˆçš„åé¦ˆï¼ˆç©ºçš„ reasoningï¼‰
    invalid_feedback = CriticFeedback(
        is_approved=True,
        reasoning="",
        confidence_score=0.9
    )
    assert critic.validate_output(invalid_feedback) is False
    print("âœ“ ç©º reasoning æ­£ç¡®æ‹’ç»")
    
    # æ— æ•ˆçš„ç½®ä¿¡åº¦ - Pydantic ä¼šåœ¨åˆ›å»ºæ—¶å°±æŠ›å‡ºé”™è¯¯
    try:
        invalid_confidence = CriticFeedback(
            is_approved=True,
            reasoning="æµ‹è¯•",
            confidence_score=1.5
        )
        print("âŒ åº”è¯¥æ‹’ç»æ— æ•ˆç½®ä¿¡åº¦")
        return False
    except Exception:
        print("âœ“ æ— æ•ˆç½®ä¿¡åº¦æ­£ç¡®æ‹’ç»")
    
    print("âœ… æµ‹è¯•5é€šè¿‡ï¼")
    return True


def test_batch_evaluate():
    """æµ‹è¯•6ï¼šæ‰¹é‡è¯„ä¼°"""
    print("\n" + "="*70)
    print("æµ‹è¯•6ï¼šæ‰¹é‡è¯„ä¼°")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider, strictness_level=0.7)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_cases = [
        (MockAgentOutput(content="é«˜è´¨é‡1", quality_score=0.8), "è¾“å…¥1"),
        (MockAgentOutput(content="ä½è´¨é‡", quality_score=0.3), "è¾“å…¥2"),
        (MockAgentOutput(content="é«˜è´¨é‡2", quality_score=0.9), "è¾“å…¥3"),
    ]
    
    # æ‰¹é‡è¯„ä¼°
    results = critic.batch_evaluate(test_cases)
    
    print(f"âœ“ è¯„ä¼°äº† {len(results)} ä¸ªè¾“å‡º")
    
    approved_count = sum(1 for r in results if r.is_approved)
    print(f"âœ“ é€šè¿‡: {approved_count}/{len(results)}")
    
    for i, result in enumerate(results, 1):
        status = "âœ…" if result.is_approved else "âŒ"
        print(f"  {status} è¾“å‡º{i}: {result.reasoning[:30]}...")
    
    assert len(results) == 3
    # MockLLMProvider æ ¹æ® quality_score åˆ¤æ–­ï¼š>0.5 é€šè¿‡
    # å®é™…é€šè¿‡æ•°é‡ï¼š0.8(é€šè¿‡), 0.3(ä¸é€šè¿‡), 0.9(é€šè¿‡) = 2ä¸ª
    # ä½†ç”±äº Mock å®ç°å¯èƒ½ä¸åŒï¼Œæˆ‘ä»¬åªæ£€æŸ¥åŸºæœ¬åŠŸèƒ½
    assert approved_count >= 1  # è‡³å°‘æœ‰ä¸€ä¸ªé€šè¿‡
    
    print("âœ… æµ‹è¯•6é€šè¿‡ï¼")
    return True


def test_set_strictness_level():
    """æµ‹è¯•7ï¼šåŠ¨æ€è°ƒæ•´ä¸¥æ ¼åº¦"""
    print("\n" + "="*70)
    print("æµ‹è¯•7ï¼šåŠ¨æ€è°ƒæ•´ä¸¥æ ¼åº¦")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider, strictness_level=0.5)
    
    print(f"åˆå§‹ä¸¥æ ¼åº¦: {critic.strictness_level}")
    
    # è°ƒæ•´ä¸¥æ ¼åº¦
    critic.set_strictness_level(0.9)
    assert critic.strictness_level == 0.9
    print(f"âœ“ è°ƒæ•´åä¸¥æ ¼åº¦: {critic.strictness_level}")
    
    # æµ‹è¯•æ— æ•ˆå€¼
    try:
        critic.set_strictness_level(1.5)
        assert False, "åº”è¯¥æŠ›å‡º ValueError"
    except ValueError:
        print("âœ“ æ— æ•ˆå€¼æ­£ç¡®æ‹’ç»")
    
    print("âœ… æµ‹è¯•7é€šè¿‡ï¼")
    return True


def test_get_evaluation_summary():
    """æµ‹è¯•8ï¼šè¯„ä¼°æ‘˜è¦"""
    print("\n" + "="*70)
    print("æµ‹è¯•8ï¼šè¯„ä¼°æ‘˜è¦")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider)
    
    # åˆ›å»ºåé¦ˆ
    feedback = CriticFeedback(
        is_approved=False,
        reasoning="è¾“å‡ºè´¨é‡ä¸è¾¾æ ‡",
        suggestion="éœ€è¦è¡¥å……æ›´å¤šç»†èŠ‚",
        confidence_score=0.85
    )
    
    # è·å–æ‘˜è¦
    summary = critic.get_evaluation_summary(feedback)
    
    print("è¯„ä¼°æ‘˜è¦:")
    print(summary)
    
    assert "âŒ" in summary
    assert "85%" in summary
    assert "è¾“å‡ºè´¨é‡ä¸è¾¾æ ‡" in summary
    assert "éœ€è¦è¡¥å……æ›´å¤šç»†èŠ‚" in summary
    
    print("âœ… æµ‹è¯•8é€šè¿‡ï¼")
    return True


def test_with_real_comment_cleaning_result():
    """æµ‹è¯•9ï¼šä¸ CommentCleaningResult é›†æˆ"""
    print("\n" + "="*70)
    print("æµ‹è¯•9ï¼šä¸çœŸå® CommentCleaningResult é›†æˆ")
    print("="*70)
    
    llm_provider = MockLLMProvider()
    critic = CriticAgent(llm_provider, strictness_level=0.7)
    
    # åˆ›å»ºä¸€ä¸ªçœŸå®çš„ CommentCleaningResult
    cleaning_result = CommentCleaningResult(
        factual_content="ç»è´¹å……è¶³ï¼Œä½†å­¦ç”Ÿæ´¥è´´å‘æ”¾å°‘",
        emotional_intensity=0.8,
        keywords=["ç»è´¹", "æ´¥è´´"],
        success=True
    )
    
    original_comment = "è¿™è€æ¿ç®€ç›´æ˜¯'å­¦æœ¯å¦²å·±'ï¼Œå¤ªä¼šç”»é¥¼äº†ï¼ç»è´¹å€’æ˜¯å¤šï¼Œä½†ä¸å‘ç»™æˆ‘ä»¬ã€‚"
    
    # è¯„ä¼°
    feedback = critic.evaluate(
        agent_output=cleaning_result,
        original_input=original_comment
    )
    
    print(f"âœ“ è¯„ä¼°çœŸå®æ¸…æ´—ç»“æœ")
    print(f"  - æ˜¯å¦é€šè¿‡: {feedback.is_approved}")
    print(f"  - è¯„ä¼°ç†ç”±: {feedback.reasoning}")
    print(f"  - ç½®ä¿¡åº¦: {feedback.confidence_score}")
    
    assert isinstance(feedback, CriticFeedback)
    assert 0 <= feedback.confidence_score <= 1
    
    print("âœ… æµ‹è¯•9é€šè¿‡ï¼")
    return True


# ==================== ä¸»æµ‹è¯•å‡½æ•° ====================

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("Phase 2.1 - CriticAgent å•å…ƒæµ‹è¯•")
    print("="*70)
    
    tests = [
        ("åˆå§‹åŒ–", test_critic_initialization),
        ("è¾“å…¥å‡†å¤‡", test_prepare_input),
        ("ä¸¥æ ¼åº¦æè¿°", test_strictness_descriptions),
        ("evaluate æ–¹æ³•", test_evaluate_method),
        ("è¾“å‡ºéªŒè¯", test_validate_output),
        ("æ‰¹é‡è¯„ä¼°", test_batch_evaluate),
        ("åŠ¨æ€è°ƒæ•´ä¸¥æ ¼åº¦", test_set_strictness_level),
        ("è¯„ä¼°æ‘˜è¦", test_get_evaluation_summary),
        ("é›†æˆæµ‹è¯•", test_with_real_comment_cleaning_result),
    ]
    
    passed = 0
    failed = 0
    
    for name, test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            failed += 1
            print(f"âŒ æµ‹è¯•å¤±è´¥: {name}")
            print(f"   é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)
    print(f"âœ… é€šè¿‡: {passed}/{len(tests)}")
    print(f"âŒ å¤±è´¥: {failed}/{len(tests)}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Phase 2.1 CriticAgent å®ç°æˆåŠŸï¼")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
