"""
Phase 1 æ¼”ç¤ºè„šæœ¬ - æ ¸éªŒå¾ªç¯æœºåˆ¶
å±•ç¤ºå¦‚ä½•åœ¨å®é™…åœºæ™¯ä¸­ä½¿ç”¨ Verification Loop
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from core.verification import VerificationLoop, AdaptiveVerificationLoop
from models.schemas import CriticFeedback, CommentCleaningResult
from pydantic import BaseModel, Field
from typing import Dict, Any


def demo_basic_verification():
    """æ¼”ç¤º1ï¼šåŸºç¡€æ ¸éªŒå¾ªç¯"""
    print("\n" + "="*70)
    print("æ¼”ç¤º1ï¼šåŸºç¡€æ ¸éªŒå¾ªç¯ - è¯„è®ºæ¸…æ´—è´¨é‡æ£€æŸ¥")
    print("="*70)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªè¯„è®ºæ¸…æ´— Agent çš„è¾“å‡º
    class CleanerOutput(BaseModel):
        factual_content: str
        quality: float
        metadata: Dict[str, Any] = Field(default_factory=dict)
    
    # åˆ›å»ºæ ¸éªŒå¾ªç¯å™¨
    loop = VerificationLoop(max_retries=3, strictness_level=0.7)
    
    # æ¨¡æ‹Ÿç”Ÿæˆå™¨ï¼ˆå®é™…åœºæ™¯ä¸­è¿™ä¼šæ˜¯ RawCommentCleaner.process()ï¼‰
    raw_comment = "è¿™è€æ¿ç®€ç›´æ˜¯'å­¦æœ¯å¦²å·±'ï¼Œå¤ªä¼šç”»é¥¼äº†ï¼ç»è´¹å€’æ˜¯å¤šï¼Œä½†ä¸å‘ç»™æˆ‘ä»¬ã€‚"
    
    attempt_count = [0]
    
    def cleaner_generator():
        attempt_count[0] += 1
        print(f"\nğŸ“ ç¬¬ {attempt_count[0]} æ¬¡å¤„ç†...")
        
        # ç¬¬ä¸€æ¬¡ï¼šæå–ä¸å¤Ÿå®Œæ•´
        if attempt_count[0] == 1:
            return CleanerOutput(
                factual_content="ç»è´¹å¤š",
                quality=0.6
            )
        # ç¬¬äºŒæ¬¡ï¼šæå–æ›´å®Œæ•´
        else:
            return CleanerOutput(
                factual_content="ç»è´¹å……è¶³ï¼Œä½†å­¦ç”Ÿæ´¥è´´å‘æ”¾å°‘",
                quality=0.85
            )
    
    # æ¨¡æ‹Ÿåˆ¤åˆ«å™¨ï¼ˆå®é™…åœºæ™¯ä¸­è¿™ä¼šæ˜¯ CriticAgent.evaluate()ï¼‰
    def quality_critic(output: CleanerOutput, context: Any) -> CriticFeedback:
        is_approved = output.quality >= 0.7
        
        if is_approved:
            reasoning = f"âœ… å†…å®¹è´¨é‡è‰¯å¥½ï¼ˆ{output.quality:.2f}ï¼‰ï¼Œäº‹å®æå–å®Œæ•´"
        else:
            reasoning = f"âŒ å†…å®¹è´¨é‡ä¸è¶³ï¼ˆ{output.quality:.2f}ï¼‰ï¼Œäº‹å®æå–ä¸å¤Ÿè¯¦ç»†"
        
        print(f"ğŸ” åˆ¤åˆ«: {reasoning}")
        
        return CriticFeedback(
            is_approved=is_approved,
            reasoning=reasoning,
            suggestion="éœ€è¦æå–æ›´å¤šå…³é”®äº‹å®ä¿¡æ¯" if not is_approved else "",
            confidence_score=0.9
        )
    
    # æ‰§è¡Œæ ¸éªŒå¾ªç¯
    print(f"åŸå§‹è¯„è®º: {raw_comment}")
    result, feedback_history = loop.execute(
        cleaner_generator,
        quality_critic,
        context=raw_comment
    )
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š æ ¸éªŒç»“æœ:")
    print(f"  - æ€»å°è¯•æ¬¡æ•°: {len(feedback_history)}")
    print(f"  - æœ€ç»ˆå†…å®¹: {result.factual_content}")
    print(f"  - è´¨é‡è¯„åˆ†: {result.quality}")
    print(f"  - æ˜¯å¦é€šè¿‡: {feedback_history[-1].is_approved}")
    
    # æ˜¾ç¤ºåé¦ˆå†å²
    print(f"\nğŸ“œ åé¦ˆå†å²:")
    for i, feedback in enumerate(feedback_history, 1):
        print(f"  ç¬¬{i}æ¬¡: {'âœ… é€šè¿‡' if feedback.is_approved else 'âŒ æœªé€šè¿‡'} - {feedback.reasoning}")


def demo_with_real_agent():
    """æ¼”ç¤º2ï¼šä¸çœŸå® Agent é›†æˆ"""
    print("\n" + "="*70)
    print("æ¼”ç¤º2ï¼šä¸ RawCommentCleaner é›†æˆä½¿ç”¨")
    print("="*70)
    
    # æ³¨æ„ï¼šè¿™éœ€è¦ LLM API é…ç½®
    print("\nâš ï¸  æ­¤æ¼”ç¤ºéœ€è¦é…ç½® LLM APIï¼ˆè·³è¿‡å®é™…è°ƒç”¨ï¼‰")
    print("é›†æˆæ–¹å¼ç¤ºä¾‹ï¼š")
    
    code_example = '''
    from core.llm_adapter import OpenAICompatibleProvider
    from agents.raw_comment_cleaner import RawCommentCleaner
    from agents.critic import CriticAgent  # Phase 2 å°†å®ç°
    
    # åˆ›å»º LLM æä¾›è€…
    llm_provider = OpenAICompatibleProvider(
        model_name="deepseek-chat",
        api_key="your-api-key",
        base_url="https://api.deepseek.com"
    )
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    cleaner = RawCommentCleaner(llm_provider)
    critic = CriticAgent(llm_provider, strictness_level=0.7)
    
    # ä½¿ç”¨æ ¸éªŒå¾ªç¯å¤„ç†
    result = cleaner.process_with_verification(
        raw_input="è¿™è€æ¿ç®€ç›´æ˜¯'å­¦æœ¯å¦²å·±'ï¼",
        critic_agent=critic,
        max_retries=3
    )
    
    # æŸ¥çœ‹åé¦ˆå†å²
    print(result.metadata['feedback_history'])
    print(result.metadata['verification_stats'])
    '''
    
    print(code_example)


def demo_adaptive_loop():
    """æ¼”ç¤º3ï¼šè‡ªé€‚åº”æ ¸éªŒå¾ªç¯"""
    print("\n" + "="*70)
    print("æ¼”ç¤º3ï¼šè‡ªé€‚åº”æ ¸éªŒå¾ªç¯ - è‡ªåŠ¨ä¼˜åŒ–é‡è¯•æ¬¡æ•°")
    print("="*70)
    
    # åˆ›å»ºè‡ªé€‚åº”å¾ªç¯å™¨
    loop = AdaptiveVerificationLoop(
        max_retries=5,
        adaptation_window=10,  # æ¯10æ¬¡æ‰§è¡Œåé‡æ–°è¯„ä¼°
        min_retries=1,
        max_max_retries=10
    )
    
    print(f"åˆå§‹ max_retries: {loop.max_retries}")
    
    # æ¨¡æ‹Ÿå¤šæ¬¡æ‰§è¡Œ
    print("\næ¨¡æ‹Ÿå¤„ç†100æ¡è¯„è®º...")
    
    class SimpleOutput(BaseModel):
        content: str
        quality: float
        metadata: Dict[str, Any] = Field(default_factory=dict)
    
    success_count = 0
    
    for i in range(100):
        # 80% çš„æƒ…å†µä¸‹é¦–æ¬¡å³æˆåŠŸ
        quality = 0.85 if i % 5 != 0 else 0.65
        
        def generator():
            return SimpleOutput(content=f"output_{i}", quality=quality)
        
        def critic(output, context):
            is_approved = output.quality >= 0.7
            return CriticFeedback(
                is_approved=is_approved,
                reasoning="é€šè¿‡" if is_approved else "æœªé€šè¿‡",
                confidence_score=0.9
            )
        
        result, _ = loop.execute(generator, critic, context=f"input_{i}")
        if result.quality >= 0.7:
            success_count += 1
        
        # æ¯10æ¬¡æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
        if (i + 1) % 10 == 0:
            stats = loop.get_statistics()
            print(f"  å¤„ç† {i+1}/100 æ¡ | "
                  f"å½“å‰ max_retries={loop.max_retries} | "
                  f"æˆåŠŸç‡={stats['success_rate']:.1%}")
    
    # æœ€ç»ˆç»Ÿè®¡
    final_stats = loop.get_statistics()
    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"  - æ€»å¤„ç†æ•°: {final_stats['total_executions']}")
    print(f"  - æˆåŠŸæ•°: {final_stats['successful_executions']}")
    print(f"  - æˆåŠŸç‡: {final_stats['success_rate']:.1%}")
    print(f"  - æœ€ç»ˆ max_retries: {loop.max_retries}")
    print(f"  - ä¼˜åŒ–è¯´æ˜: ç”±äºæˆåŠŸç‡é«˜ï¼Œç³»ç»Ÿè‡ªåŠ¨é™ä½äº†é‡è¯•æ¬¡æ•°ä»¥æé«˜æ•ˆç‡")


def demo_statistics():
    """æ¼”ç¤º4ï¼šç»Ÿè®¡ä¿¡æ¯æ”¶é›†"""
    print("\n" + "="*70)
    print("æ¼”ç¤º4ï¼šç»Ÿè®¡ä¿¡æ¯æ”¶é›†ä¸åˆ†æ")
    print("="*70)
    
    loop = VerificationLoop(max_retries=3, enable_logging=False)
    
    class Output(BaseModel):
        value: int
        metadata: Dict[str, Any] = Field(default_factory=dict)
    
    # æ¨¡æ‹Ÿä¸åŒåœºæ™¯
    scenarios = [
        ("é«˜è´¨é‡è¾“å…¥", 0.95, True),
        ("ä¸­ç­‰è´¨é‡", 0.75, True),
        ("ä½è´¨é‡è¾“å…¥", 0.45, False),
        ("é«˜è´¨é‡è¾“å…¥", 0.90, True),
        ("æä½è´¨é‡", 0.30, False),
    ]
    
    print("\nå¤„ç†ä¸åŒè´¨é‡çš„è¾“å…¥...")
    for name, quality, expected_pass in scenarios:
        def gen():
            return Output(value=int(quality * 100))
        
        def critic(output, context):
            is_approved = output.value >= 70
            return CriticFeedback(
                is_approved=is_approved,
                reasoning=f"å€¼ä¸º {output.value}",
                confidence_score=0.9
            )
        
        result, history = loop.execute(gen, critic, context=name)
        status = "âœ…" if history[-1].is_approved else "âŒ"
        print(f"  {status} {name}: å€¼={result.value}, å°è¯•={len(history)}æ¬¡")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats = loop.get_statistics()
    print(f"\nğŸ“Š æ±‡æ€»ç»Ÿè®¡:")
    print(f"  - æ€»æ‰§è¡Œ: {stats['total_executions']} æ¬¡")
    print(f"  - æˆåŠŸ: {stats['successful_executions']} æ¬¡")
    print(f"  - å¤±è´¥: {stats['failed_executions']} æ¬¡")
    print(f"  - æˆåŠŸç‡: {stats['success_rate']:.1%}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("Phase 1 æ ¸éªŒå¾ªç¯æœºåˆ¶ - åŠŸèƒ½æ¼”ç¤º")
    print("="*70)
    
    demos = [
        demo_basic_verification,
        demo_with_real_agent,
        demo_adaptive_loop,
        demo_statistics
    ]
    
    for demo in demos:
        try:
            demo()
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("="*70)
    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("  1. VerificationLoop å®ç°äº† Agent Output â†’ Critic Check â†’ Pass/Retry å¾ªç¯")
    print("  2. å¯ä»¥è½»æ¾é›†æˆåˆ°ä»»ä½•ç»§æ‰¿è‡ª BaseAgent çš„æ™ºèƒ½ä½“ä¸­")
    print("  3. é€šè¿‡ process_with_verification() æ–¹æ³•ä½¿ç”¨")
    print("  4. åé¦ˆå†å²ä¿å­˜åœ¨ç»“æœçš„ metadata ä¸­")
    print("  5. AdaptiveVerificationLoop å¯ä»¥è‡ªåŠ¨ä¼˜åŒ–é‡è¯•æ¬¡æ•°")
    print("\nğŸ“š ä¸‹ä¸€æ­¥: Phase 2 - å®ç° CriticAgent å’Œå…¶ä»–åç«¯æ™ºèƒ½ä½“")


if __name__ == "__main__":
    main()
