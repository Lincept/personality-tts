#!/usr/bin/env python3
"""
DEL Agent - ç»Ÿä¸€å…¥å£
æ”¯æŒæ–‡æœ¬äº¤äº’å’Œè¯­éŸ³äº¤äº’åŒæ¨¡å¼

ç‰ˆæœ¬ï¼š1.0.0
åˆ›å»ºï¼šPhase 4.2
"""

import asyncio
import argparse
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from del_agent.frontend.orchestrator import FrontendOrchestrator
from del_agent.frontend.voice_adapter import VoiceAdapter, start_voice_conversation
from del_agent.core.llm_adapter import LLMProvider, OpenAICompatibleProvider
from del_agent.utils.config import ConfigManager
from del_agent.backend.factory import DataFactoryPipeline
from del_agent.storage.vector_store import create_vector_store
from del_agent.models.schemas import RawReview
import json
from datetime import datetime
from typing import List, Optional
import os

# é»˜è®¤ä¸è¾“å‡º loggingï¼ˆæœ¬é¡¹ç›®è°ƒè¯•è¾“å‡ºä½¿ç”¨ print + æ ‡å¿—ä½æ§åˆ¶ï¼‰
logging.getLogger().setLevel(logging.WARNING)


def _truncate(text: str, max_len: int = 180) -> str:
    if text is None:
        return ""
    text = str(text).replace("\n", " ")
    return text if len(text) <= max_len else (text[: max_len - 3] + "...")


class DELAgent:
    """
    DEL Agent ä¸»åº”ç”¨
    
    åŠŸèƒ½ï¼š
    1. æ–‡æœ¬æ¨¡å¼ï¼šä½¿ç”¨ FrontendOrchestrator è¿›è¡Œæ–‡æœ¬äº¤äº’
    2. è¯­éŸ³æ¨¡å¼ï¼šä½¿ç”¨ VoiceAdapter è¿›è¡Œç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯
    3. æ”¯æŒå‘½ä»¤è¡Œå‚æ•°åˆ‡æ¢æ¨¡å¼
    """
    
    def __init__(
        self,
        config_path: str = "del_agent/config/settings.yaml",
        trace_frontend: bool = False,
        trace_backend: bool = False
    ):
        """
        åˆå§‹åŒ– DEL Agent
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config_manager = ConfigManager(config_path)
        self.orchestrator = None
        self.llm_provider = None

        self.trace_frontend = trace_frontend
        self.trace_backend = trace_backend
    
    def load_configuration(self) -> None:
        """åŠ è½½é…ç½®ï¼ˆå·²é€šè¿‡ ConfigManager è‡ªåŠ¨åŠ è½½ï¼‰"""
        print(f"[CONFIG] loaded: {self.config_path}")
    
    def initialize_text_mode(self) -> None:
        """åˆå§‹åŒ–æ–‡æœ¬æ¨¡å¼ç»„ä»¶"""
        print("[INIT] text mode...")

        llm_config = self.config_manager.get_llm_config('doubao')
        if not llm_config.api_key:
            raise RuntimeError("æœªæ‰¾åˆ°è±†åŒ… API Keyï¼ˆè¯·è®¾ç½® ARK_API_KEY æˆ– DOBAO_API_KEYï¼‰")

        self.llm_provider = OpenAICompatibleProvider(
            model_name=llm_config.model_name,
            api_key=llm_config.api_key,
            base_url=llm_config.base_url,
            timeout=llm_config.timeout,
            api_secret=getattr(llm_config, "api_secret", None)
        )

        mem_config = (
            self.config_manager.get_global_config("mem0_config")
            or self.config_manager.get_global_config("memory")
            or {}
        )
        vector_store = create_vector_store(mem_config)

        backend_pipeline = DataFactoryPipeline(
            llm_provider=self.llm_provider,
            enable_verification=False,
            max_retries=3,
            strictness_level=0.7,
            vector_store=vector_store,
            trace_backend=self.trace_backend,
            trace_print=print
        )

        self.orchestrator = FrontendOrchestrator(
            llm_provider=self.llm_provider,
            backend_pipeline=backend_pipeline,
            enable_rag=True,
            rag_retriever=vector_store,
            trace_frontend=self.trace_frontend,
            trace_print=print
        )

        print("[INIT] text mode ready")
    
    async def run_text_mode(self) -> None:
        """
        è¿è¡Œæ–‡æœ¬äº¤äº’æ¨¡å¼
        
        ä½¿ç”¨ FrontendOrchestrator å¤„ç†ç”¨æˆ·è¾“å…¥
        """
        print("=" * 60)
        print("DEL Agent - æ–‡æœ¬äº¤äº’æ¨¡å¼")
        print("=" * 60)
        print("æç¤ºï¼šè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("æç¤ºï¼šè¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("-" * 60)
        
        user_id = "default_user"

        if not self.orchestrator:
            self.initialize_text_mode()
        
        while True:
            try:
                # è¯»å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nç”¨æˆ·: ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nå†è§ï¼")
                    break
                
                if user_input.lower() == 'clear':
                    if self.orchestrator:
                        self.orchestrator.clear_conversation(user_id)
                    print("âœ“ å¯¹è¯å†å²å·²æ¸…ç©º")
                    continue
                
                # å¤„ç†ç”¨æˆ·è¾“å…¥
                if self.orchestrator:
                    if self.trace_frontend or self.trace_backend:
                        print("-" * 60)
                        print(f"[TRACE] frontend={self.trace_frontend} backend={self.trace_backend}")
                        print(f"[USER] {_truncate(user_input, 220)}")
                    result = await self.orchestrator.process_user_input(
                        user_id=user_id,
                        user_input=user_input
                    )
                    
                    if result["success"]:
                        print(f"\nåŠ©æ‰‹: {result['response_text']}")
                        
                        # æ˜¾ç¤ºæ„å›¾ç±»å‹ï¼ˆè°ƒè¯•ä¿¡æ¯ï¼‰
                        intent = result.get("intent_type", "unknown")
                        print(f"\n[ç»“æœ] æ„å›¾: {intent}, è€—æ—¶: {result['execution_time']:.2f}s")
                    else:
                        print(f"\n[é”™è¯¯] {result.get('error_message', 'å¤„ç†å¤±è´¥')}")
                else:
                    # Orchestrator æœªåˆå§‹åŒ–ï¼Œç®€å•å›æ˜¾
                    print(f"\nåŠ©æ‰‹: [Echo] {user_input}")
                    print("\n[æ³¨æ„] FrontendOrchestrator æœªåˆå§‹åŒ–ï¼Œå½“å‰ä¸ºå›æ˜¾æ¨¡å¼")
            
            except KeyboardInterrupt:
                print("\n\nå†è§ï¼")
                break
            except EOFError:
                # stdin å…³é—­ï¼ˆç®¡é“è¾“å…¥ç»“æŸï¼‰ï¼Œä¼˜é›…é€€å‡º
                print("\n[EOF] è¾“å…¥ç»“æŸï¼Œé€€å‡º")
                break
            except Exception as e:
                print(f"\n[é”™è¯¯] å¤„ç†è¾“å…¥æ—¶å‡ºé”™: {type(e).__name__}: {e}")
    
    async def run_voice_mode(
        self,
        audio_file: str = "",
        enable_memory: bool = False,
        enable_aec: bool = False
    ) -> None:
        """
        è¿è¡Œè¯­éŸ³äº¤äº’æ¨¡å¼
        
        ä½¿ç”¨ VoiceAdapter è¿›è¡Œç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            enable_memory: æ˜¯å¦å¯ç”¨è®°å¿†å­˜å‚¨
            enable_aec: æ˜¯å¦å¯ç”¨å›å£°æ¶ˆé™¤
        """
        print("=" * 60)
        print("DEL Agent - è¯­éŸ³äº¤äº’æ¨¡å¼")
        print("=" * 60)
        
        if audio_file:
            print(f"éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        else:
            print("è¾“å…¥æº: éº¦å…‹é£")
        
        print(f"è®°å¿†å­˜å‚¨: {'å¯ç”¨' if enable_memory else 'ç¦ç”¨'}")
        print(f"å›å£°æ¶ˆé™¤: {'å¯ç”¨' if enable_aec else 'ç¦ç”¨'}")
        print("-" * 60)
        print("æŒ‰ Ctrl+C ç»“æŸå¯¹è¯")
        print("=" * 60)
        print()
        
        # å¯åŠ¨è¯­éŸ³å¯¹è¯
        mode = "audio"
        await start_voice_conversation(
            mode=mode,
            audio_file=audio_file if audio_file else None,
            enable_memory=enable_memory,
            enable_aec=enable_aec
        )
    
    async def run_data_processing(
        self,
        limit: Optional[int] = None,
        output_dir: Optional[str] = None
    ) -> None:
        """
        è¿è¡Œæ•°æ®å¤„ç†æ¨¡å¼
        
        å¤„ç†data/professorsç›®å½•ä¸­çš„è¯„è®ºæ•°æ®
        
        Args:
            limit: é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ŒNoneè¡¨ç¤ºå¤„ç†å…¨éƒ¨
            output_dir: è¾“å‡ºç›®å½•ï¼Œä¿å­˜å¤„ç†ç»“æœ
        """
        print("=" * 60)
        print("DEL Agent - æ•°æ®å¤„ç†æ¨¡å¼")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰æ•™æˆæ•°æ®æ–‡ä»¶
        professors_dir = Path(__file__).parent / "data" / "professors"
        if not professors_dir.exists():
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {professors_dir}")
            return
        
        json_files = list(professors_dir.glob("*.json"))
        if not json_files:
            print(f"âŒ é”™è¯¯: {professors_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
            return
        
        # é™åˆ¶å¤„ç†æ•°é‡
        if limit and limit > 0:
            json_files = json_files[:limit]
            print(f"å¤„ç†æ–‡ä»¶æ•°: {len(json_files)} (é™åˆ¶å‰ {limit} ä¸ª)")
        else:
            print(f"å¤„ç†æ–‡ä»¶æ•°: {len(json_files)} (å…¨éƒ¨)")
        
        print("-" * 60)
        
        # åˆå§‹åŒ–LLM Provider
        try:
            # ä»é…ç½®ç®¡ç†å™¨è·å–LLMé…ç½®
            llm_config = self.config_manager.get_llm_config('doubao')
            
            # åˆ›å»ºOpenAIå…¼å®¹çš„Provider
            llm_provider = OpenAICompatibleProvider(
                model_name=llm_config.model_name,
                api_key=llm_config.api_key,
                base_url=llm_config.base_url,
                timeout=llm_config.timeout
            )
            print(f"âœ“ LLM Provider åˆå§‹åŒ–æˆåŠŸ (model: {llm_config.model_name})")
        except Exception as e:
            print(f"âŒ LLM Provider åˆå§‹åŒ–å¤±è´¥: {e}")
            return
        
        # åˆå§‹åŒ–æ•°æ®å·¥å‚æµæ°´çº¿
        try:
            pipeline = DataFactoryPipeline(
                llm_provider=llm_provider,
                enable_verification=False,  # å¯é…ç½®
                max_retries=3,
                strictness_level=0.7,
                trace_backend=self.trace_backend,
                trace_print=print
            )
            print("âœ“ DataFactoryPipeline åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ DataFactoryPipeline åˆå§‹åŒ–å¤±è´¥: {e}")
            return
        
        print("-" * 60)
        print()
        
        # æ”¶é›†æ‰€æœ‰è¯„è®º
        all_reviews = []
        file_review_mapping = []  # è®°å½•æ¯ä¸ªreviewæ¥è‡ªå“ªä¸ªæ–‡ä»¶
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå–è¯„è®º
                reviews = data.get("data", {}).get("reviews", [])
                professor_info = data.get("input", {})
                
                print(f"ğŸ“„ {json_file.name}: {len(reviews)} æ¡è¯„è®º")
                
                # è½¬æ¢ä¸ºRawReviewæ ¼å¼
                for review in reviews:
                    description = review.get("description", "").strip()
                    if not description:
                        continue
                    
                    # è§£æcreated_atæ—¶é—´æˆ³
                    created_at_str = review.get("created_at")
                    try:
                        timestamp = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                    except:
                        timestamp = datetime.now()
                    
                    # æ„å»ºsource_metadata
                    source_metadata = {
                        "professor": professor_info.get("professor", ""),
                        "university": professor_info.get("university", ""),
                        "department": professor_info.get("department", ""),
                        "review_id": review.get("id", ""),
                        "sha1": data.get("sha1", ""),
                        "anonymous": review.get("anonymous", True),
                        "student_relation": review.get("studentProfRelation", 0),
                        "academic": review.get("academic", 0),
                        "job_potential": review.get("jobPotential", 0),
                        "file": json_file.name
                    }
                    
                    raw_review = RawReview(
                        content=description,
                        source_metadata=source_metadata,
                        timestamp=timestamp
                    )
                    
                    all_reviews.append(raw_review)
                    file_review_mapping.append({
                        "file": json_file.name,
                        "professor": professor_info.get("display", "Unknown")
                    })
            
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {json_file.name} æ—¶å‡ºé”™: {e}")
                continue
        
        print()
        print("=" * 60)
        print(f"å…±æ”¶é›†åˆ° {len(all_reviews)} æ¡è¯„è®ºï¼Œå¼€å§‹å¤„ç†...")
        print("=" * 60)
        print()
        
        if not all_reviews:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¯„è®ºæ•°æ®")
            return
        
        # æ‰¹é‡å¤„ç†è¯„è®º
        try:
            results = await pipeline.process_batch(
                all_reviews,
                continue_on_error=True
            )
            
            print()
            print("=" * 60)
            print("å¤„ç†å®Œæˆ")
            print("=" * 60)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = pipeline.get_statistics()
            print(f"æ€»å¤„ç†æ•°: {stats['total_processed']}")
            print(f"æˆåŠŸæ•°: {stats['successful']}")
            print(f"å¤±è´¥æ•°: {stats['failed']}")
            print(f"æˆåŠŸç‡: {stats['success_rate']*100:.1f}%")
            
            # ä¿å­˜ç»“æœ
            if output_dir:
                output_path = Path(output_dir)
            else:
                output_path = Path(__file__).parent / "data" / "processed"
            
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜å¤„ç†ç»“æœ
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = output_path / f"processed_reviews_{timestamp_str}.json"
            
            output_data = {
                "metadata": {
                    "processed_at": datetime.now().isoformat(),
                    "total_files": len(json_files),
                    "total_reviews": len(all_reviews),
                    "statistics": stats
                },
                "results": [
                    {
                        "mentor_id": result.mentor_id,
                        "dimension": result.dimension,
                        "fact_content": result.fact_content,
                        "original_nuance": result.original_nuance,
                        "weight_score": result.weight_score,
                        "tags": result.tags,
                        "last_updated": result.last_updated.isoformat(),
                        "source": file_review_mapping[i] if i < len(file_review_mapping) else {}
                    }
                    for i, result in enumerate(results)
                ]
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            print()
            print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            logger.error(f"Batch processing error: {e}", exc_info=True)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="DEL Agent - å¯¼å¸ˆè¯„ä»·ä¸ä¿¡æ¯æå–æ™ºèƒ½ä½“",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ–‡æœ¬äº¤äº’æ¨¡å¼
  python main.py --mode text
  
  # è¯­éŸ³äº¤äº’æ¨¡å¼ï¼ˆéº¦å…‹é£ï¼‰
  python main.py --mode voice
  
  # è¯­éŸ³äº¤äº’æ¨¡å¼ï¼ˆéŸ³é¢‘æ–‡ä»¶ï¼‰
  python main.py --mode voice --audio data/test.wav
  
  # æ•°æ®å¤„ç†æ¨¡å¼ï¼ˆå¤„ç†å…¨éƒ¨æ•°æ®ï¼‰
  python main.py --mode process
  
  # æ•°æ®å¤„ç†æ¨¡å¼ï¼ˆå¤„ç†å‰10ä¸ªæ–‡ä»¶ï¼‰
  python main.py --mode process --limit 10
  
  # æ•°æ®å¤„ç†æ¨¡å¼ï¼ˆæŒ‡å®šè¾“å‡ºç›®å½•ï¼‰
  python main.py --mode process --output ./results
  
  # å¯ç”¨è®°å¿†å­˜å‚¨
  python main.py --mode voice --memory
  
  # å¯ç”¨å›å£°æ¶ˆé™¤
  python main.py --mode voice --aec
        """
    )
    
    parser.add_argument(
        "--mode",
        type=str,
        choices=["text", "voice", "process"],
        default="text",
        help="è¿è¡Œæ¨¡å¼ï¼štextï¼ˆæ–‡æœ¬äº¤äº’ï¼‰ã€voiceï¼ˆè¯­éŸ³äº¤äº’ï¼‰æˆ– processï¼ˆæ•°æ®å¤„ç†ï¼‰"
    )
    
    parser.add_argument(
        "--audio",
        type=str,
        default="",
        help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆä»…åœ¨è¯­éŸ³æ¨¡å¼ï¼‰"
    )
    
    parser.add_argument(
        "--memory",
        action="store_true",
        help="å¯ç”¨è®°å¿†å­˜å‚¨ï¼ˆVikingDBï¼‰"
    )
    
    parser.add_argument(
        "--aec",
        action="store_true",
        help="å¯ç”¨å›å£°æ¶ˆé™¤ï¼ˆAECï¼‰"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default="del_agent/config/settings.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¯ç”¨è°ƒè¯•æ¨¡å¼"
    )

    parser.add_argument(
        "--trace-frontend",
        action="store_true",
        help="è¾“å‡ºå‰ç«¯å„æ¨¡å—è¾“å…¥/è¾“å‡ºï¼ˆInfoExtractor/Persona/è·¯ç”±ç­‰ï¼‰"
    )

    parser.add_argument(
        "--trace-backend",
        action="store_true",
        help="è¾“å‡ºåç«¯å„æ¨¡å—è¾“å…¥/è¾“å‡ºï¼ˆCleaner/SlangDecoder/Weigher/Compressor ç­‰ï¼‰"
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆä»…åœ¨processæ¨¡å¼ï¼‰"
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆä»…åœ¨processæ¨¡å¼ï¼‰"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        # debug ä»…ç”¨äºå¼‚å¸¸å †æ ˆï¼›å¸¸è§„è¿‡ç¨‹è¾“å‡ºä»ä½¿ç”¨ print + trace æ ‡å¿—ä½
        logging.getLogger().setLevel(logging.WARNING)
    
    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = DELAgent(
        config_path=args.config,
        trace_frontend=args.trace_frontend,
        trace_backend=args.trace_backend
    )
    
    try:
        # åŠ è½½é…ç½®
        app.load_configuration()
        
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == "text":
            # app.initialize_text_mode()
            await app.run_text_mode()
        elif args.mode == "process":
            # æ•°æ®å¤„ç†æ¨¡å¼
            await app.run_data_processing(
                limit=args.limit,
                output_dir=args.output
            )
        else:  # voice
            # æ£€æŸ¥ç¯å¢ƒé…ç½®
            is_valid, missing = VoiceAdapter.validate_config()
            if not is_valid:
                print(f"âŒ è¯­éŸ³æ¨¡å¼é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘: {', '.join(missing)}")
                print("\nè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
                print("  export DOUBAO_APP_ID=your_app_id")
                print("  export DOUBAO_ACCESS_KEY=your_access_key")
                print("\næˆ–åˆ›å»º doubao_sample/.env æ–‡ä»¶ï¼ˆå‚è€ƒ .env.exampleï¼‰")
                sys.exit(1)
            
            await app.run_voice_mode(
                audio_file=args.audio,
                enable_memory=args.memory,
                enable_aec=args.aec
            )
    
    except KeyboardInterrupt:
        logger.info("Application interrupted by user")
    except Exception as e:
        logger.error(f"Application error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
