"""
WebRTC AEC å¤„ç†å™¨ - åŸºäºå®˜æ–¹ WebRTC åº“
ç”¨äºå›å£°æ¶ˆé™¤ï¼Œè§£å†³è¯­éŸ³åŠ©æ‰‹ä¸­çš„å›å£°é—®é¢˜
"""
import platform
from collections import deque
from typing import Optional
import numpy as np
import sys
import os
import threading

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
src_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

try:
    from . import WebRTCAudioProcessing, create_default_config
    WEBRTC_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸ WebRTC AEC åº“åŠ è½½å¤±è´¥: {e}")
    WEBRTC_AVAILABLE = False


class WebRTCAECProcessor:
    """
    WebRTC å›å£°æ¶ˆé™¤å¤„ç†å™¨
    ä¸“é—¨ç”¨äºå¤„ç†å‚è€ƒä¿¡å·ï¼ˆæ‰¬å£°å™¨è¾“å‡ºï¼‰å’Œéº¦å…‹é£è¾“å…¥çš„ AEC
    """

    def __init__(self, sample_rate: int = 16000):
        """
        åˆå§‹åŒ– AEC å¤„ç†å™¨

        Args:
            sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000Hzï¼‰
        """
        self.sample_rate = sample_rate
        self._platform = platform.system().lower()
        self._is_macos = self._platform == "darwin"

        # WebRTC APM å®ä¾‹
        self.apm = None
        self.capture_config = None
        self.render_config = None

        # å‚è€ƒä¿¡å·ç¼“å†²åŒº
        self._reference_buffer = deque()
        self._webrtc_frame_size = 160  # WebRTC æ ‡å‡†ï¼š16kHz, 10ms = 160 samples

        # çŠ¶æ€æ ‡å¿—
        self._is_initialized = False

        # çº¿ç¨‹é”ï¼ˆä¿æŠ¤ WebRTC APM è°ƒç”¨ï¼‰
        self._lock = threading.Lock()
        
        # è°ƒè¯•å’Œç»Ÿè®¡
        self._debug = False  # è®¾ç½®ä¸º True å¯ä»¥çœ‹åˆ°è¯¦ç»†æ—¥å¿—
        self._stats = {
            'frames_processed': 0,
            'reference_frames_added': 0,
            'zero_reference_count': 0,
        }

        # åˆå§‹åŒ–
        self._initialize()

    def _initialize(self):
        """åˆå§‹åŒ– WebRTC AEC - å‚è€ƒ py-xiaozhi ä¼˜åŒ–é…ç½®"""
        if not self._is_macos:
            print(f"âš ï¸ {self._platform.capitalize()} å¹³å°æš‚ä¸æ”¯æŒ WebRTC AEC")
            return

        if not WEBRTC_AVAILABLE:
            print("âš ï¸ WebRTC åº“ä¸å¯ç”¨")
            return

        try:
            # åˆ›å»º WebRTC APM å®ä¾‹
            self.apm = WebRTCAudioProcessing()

            # åˆ›å»ºé…ç½® - å‚è€ƒ py-xiaozhi çš„ä¼˜åŒ–é…ç½®
            apm_config = create_default_config()

            # Pipeline é…ç½® - ä½¿ç”¨ WebRTC ä¼˜åŒ–é¢‘ç‡
            apm_config.pipeline_config.maximum_internal_processing_rate = 16000  # WebRTC ä¼˜åŒ–é¢‘ç‡
            apm_config.pipeline_config.multi_channel_render = False
            apm_config.pipeline_config.multi_channel_capture = False

            # å¯ç”¨å›å£°æ¶ˆé™¤ - ä½¿ç”¨æ ‡å‡†æ¨¡å¼
            apm_config.echo.enabled = True
            apm_config.echo.mobile_mode = False  # æ ‡å‡†æ¨¡å¼ï¼Œéç§»åŠ¨æ¨¡å¼
            apm_config.echo.enforce_high_pass_filtering = True  # å¼ºåˆ¶é«˜é€šæ»¤æ³¢

            # å¯ç”¨å™ªå£°æŠ‘åˆ¶ - ä¸­ç­‰çº§åˆ«ï¼ˆé¿å…è¿‡åº¦æŠ‘åˆ¶ï¼‰
            apm_config.noise_suppress.enabled = True
            apm_config.noise_suppress.noise_level = 1  # MODERATEï¼ˆä¸­ç­‰ï¼‰
            apm_config.noise_suppress.analyze_linear_aec_output_when_available = True

            # å¯ç”¨é«˜é€šæ»¤æ³¢å™¨
            apm_config.high_pass.enabled = True
            apm_config.high_pass.apply_in_full_band = True

            # ç¦ç”¨ PreAmplifierï¼ˆé¿å…å¤±çœŸï¼‰
            apm_config.pre_amp.enabled = False
            apm_config.pre_amp.fixed_gain_factor = 1.0

            # ç¦ç”¨ LevelAdjustmentï¼ˆå‡å°‘å¤„ç†å†²çªï¼‰
            apm_config.level_adjustment.enabled = False

            # ç¦ç”¨ TransientSuppressionï¼ˆé¿å…åˆ‡å‰²è¯­éŸ³ï¼‰
            apm_config.transient_suppress.enabled = False

            # å¯ç”¨ GainController1 - è½»åº¦å¢ç›Šæ§åˆ¶
            apm_config.gain_control1.enabled = True
            apm_config.gain_control1.controller_mode = 1  # ADAPTIVE_DIGITAL
            apm_config.gain_control1.target_level_dbfs = 3
            apm_config.gain_control1.compression_gain_db = 9
            apm_config.gain_control1.enable_limiter = True

            # ç¦ç”¨ GainController2ï¼ˆé¿å…å†²çªï¼‰
            apm_config.gain_control2.enabled = False

            # åº”ç”¨é…ç½®
            result = self.apm.apply_config(apm_config)
            if result != 0:
                raise RuntimeError(f"WebRTC APM é…ç½®å¤±è´¥ï¼Œé”™è¯¯ç : {result}")

            # åˆ›å»ºæµé…ç½®
            self.capture_config = self.apm.create_stream_config(self.sample_rate, 1)
            self.render_config = self.apm.create_stream_config(self.sample_rate, 1)

            # è®¾ç½®æµå»¶è¿Ÿ - å…³é”®ä¿®å¤ï¼å‚è€ƒ py-xiaozhi
            self.apm.set_stream_delay_ms(40)  # 40ms å»¶è¿Ÿï¼ˆè€ƒè™‘å®é™…ä¼ æ’­å’Œå¤„ç†å»¶è¿Ÿï¼‰

            self._is_initialized = True
            print("âœ… WebRTC AEC åˆå§‹åŒ–å®Œæˆï¼ˆä¼˜åŒ–é…ç½®ï¼‰")
            print("   - å›å£°æ¶ˆé™¤: å·²å¯ç”¨ï¼ˆæ ‡å‡†æ¨¡å¼ï¼‰")
            print("   - å™ªå£°æŠ‘åˆ¶: MODERATEï¼ˆä¸­ç­‰ï¼‰")
            print("   - é«˜é€šæ»¤æ³¢: å·²å¯ç”¨")
            print("   - æµå»¶è¿Ÿ: 40msï¼ˆä¼˜åŒ–ï¼‰")
            print("   - å¢ç›Šæ§åˆ¶: è‡ªé€‚åº”æ•°å­—")

        except Exception as e:
            print(f"âŒ WebRTC AEC åˆå§‹åŒ–å¤±è´¥: {e}")
            self._is_initialized = False

    def add_reference(self, reference_audio: np.ndarray):
        """
        æ·»åŠ å‚è€ƒä¿¡å·ï¼ˆæ‰¬å£°å™¨æ’­æ”¾çš„éŸ³é¢‘ï¼‰

        Args:
            reference_audio: å‚è€ƒä¿¡å·ï¼ˆint16 æˆ– float32ï¼‰
        """
        if not self._is_initialized:
            return

        # è½¬æ¢ä¸º int16
        if reference_audio.dtype == np.float32:
            # float32 èŒƒå›´ [-1.0, 1.0] è½¬æ¢ä¸º int16 èŒƒå›´ [-32768, 32767]
            reference_audio = np.clip(reference_audio * 32768.0, -32768, 32767).astype(np.int16)
        elif reference_audio.dtype != np.int16:
            reference_audio = reference_audio.astype(np.int16)

        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self._reference_buffer.extend(reference_audio)
        self._stats['reference_frames_added'] += len(reference_audio) // self._webrtc_frame_size

        # ä¿æŒç¼“å†²åŒºå¤§å°åˆç†ï¼ˆä¿ç•™ 500ms ç”¨äºå»¶è¿Ÿè¡¥å¿ï¼‰
        max_buffer_size = self._webrtc_frame_size * 50  # 500ms @ 16kHz
        while len(self._reference_buffer) > max_buffer_size:
            self._reference_buffer.popleft()
        
        if self._debug and len(self._reference_buffer) > 0:
            print(f"ğŸ”Š å‚è€ƒä¿¡å·: +{len(reference_audio)} samples, ç¼“å†²åŒº: {len(self._reference_buffer)} samples ({len(self._reference_buffer)/160:.1f} å¸§)")

    def process(self, capture_audio: np.ndarray) -> np.ndarray:
        """
        å¤„ç†éº¦å…‹é£éŸ³é¢‘ï¼Œåº”ç”¨ AEC

        Args:
            capture_audio: éº¦å…‹é£é‡‡é›†çš„éŸ³é¢‘æ•°æ®ï¼ˆint16ï¼‰

        Returns:
            å¤„ç†åçš„éŸ³é¢‘æ•°æ®ï¼ˆint16ï¼‰
        """
        if not self._is_initialized or self.apm is None:
            return capture_audio

        # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤ WebRTC APM è°ƒç”¨
        with self._lock:
            try:
                # æ›´æ–°ç»Ÿè®¡
                self._stats['frames_processed'] += 1
                
                # æ£€æŸ¥è¾“å…¥å¸§å¤§å°æ˜¯å¦ä¸º WebRTC å¸§å¤§å°çš„æ•´æ•°å€
                if len(capture_audio) % self._webrtc_frame_size != 0:
                    print(f"âš ï¸ éŸ³é¢‘å¸§å¤§å°ä¸æ˜¯ WebRTC å¸§çš„æ•´æ•°å€: {len(capture_audio)}")
                    return capture_audio

                # è®¡ç®—éœ€è¦åˆ†å‰²çš„å—æ•°
                num_chunks = len(capture_audio) // self._webrtc_frame_size

                if num_chunks == 1:
                    # 10ms å¸§ï¼Œç›´æ¥å¤„ç†
                    result = self._process_single_frame(capture_audio)
                else:
                    # 20ms/40ms/60ms å¸§ï¼Œåˆ†å‰²å¤„ç†
                    result = self._process_chunked_frames(capture_audio, num_chunks)
                
                # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                if self._debug and self._stats['frames_processed'] % 100 == 0:
                    print(f"ğŸ“Š AEC ç»Ÿè®¡: å·²å¤„ç† {self._stats['frames_processed']} å¸§, "
                          f"å‚è€ƒå¸§ {self._stats['reference_frames_added']}, "
                          f"é›¶å‚è€ƒ {self._stats['zero_reference_count']}")
                
                return result

            except Exception as e:
                print(f"âš ï¸ AEC å¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return capture_audio

    def _process_single_frame(self, capture_audio: np.ndarray) -> np.ndarray:
        """å¤„ç†å•ä¸ª 10ms WebRTC å¸§"""
        import ctypes

        try:
            # ç¡®ä¿è¾“å…¥æ˜¯æ­£ç¡®çš„ç±»å‹å’Œå¤§å°
            if len(capture_audio) != self._webrtc_frame_size:
                print(f"âš ï¸ å¸§å¤§å°ä¸åŒ¹é…: {len(capture_audio)} != {self._webrtc_frame_size}")
                return capture_audio

            # ç¡®ä¿æ˜¯ int16 ç±»å‹
            if capture_audio.dtype != np.int16:
                capture_audio = capture_audio.astype(np.int16)

            # è·å–å‚è€ƒä¿¡å·
            reference_audio = self._get_reference_frame(self._webrtc_frame_size)

            # ç¡®ä¿å‚è€ƒä¿¡å·ä¹Ÿæ˜¯æ­£ç¡®çš„ç±»å‹å’Œå¤§å°
            if len(reference_audio) != self._webrtc_frame_size:
                reference_audio = np.zeros(self._webrtc_frame_size, dtype=np.int16)

            # åˆ›å»º ctypes ç¼“å†²åŒº - ä½¿ç”¨ python3.7 é¡¹ç›®çš„æ–¹å¼
            capture_buffer = (ctypes.c_short * self._webrtc_frame_size)(*capture_audio)
            reference_buffer = (ctypes.c_short * self._webrtc_frame_size)(*reference_audio)

            processed_capture = (ctypes.c_short * self._webrtc_frame_size)()
            processed_reference = (ctypes.c_short * self._webrtc_frame_size)()

            # é¦–å…ˆå¤„ç†å‚è€ƒä¿¡å·ï¼ˆrender streamï¼‰
            render_result = self.apm.process_reverse_stream(
                reference_buffer,
                self.render_config,
                self.render_config,
                processed_reference,
            )

            if render_result != 0:
                print(f"âš ï¸ å‚è€ƒä¿¡å·å¤„ç†å¤±è´¥ï¼Œé”™è¯¯ç : {render_result}")

            # ç„¶åå¤„ç†é‡‡é›†ä¿¡å·ï¼ˆcapture streamï¼‰
            capture_result = self.apm.process_stream(
                capture_buffer,
                self.capture_config,
                self.capture_config,
                processed_capture,
            )

            if capture_result != 0:
                print(f"âš ï¸ é‡‡é›†ä¿¡å·å¤„ç†å¤±è´¥ï¼Œé”™è¯¯ç : {capture_result}")
                return capture_audio

            # è½¬æ¢å› numpy æ•°ç»„
            return np.array(processed_capture, dtype=np.int16)

        except Exception as e:
            print(f"âš ï¸ AEC å¸§å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return capture_audio

    def _process_chunked_frames(self, capture_audio: np.ndarray, num_chunks: int) -> np.ndarray:
        """åˆ†å‰²å¤„ç†å¤§å¸§ï¼ˆ20ms/40ms/60ms ç­‰ï¼‰"""
        processed_chunks = []

        for i in range(num_chunks):
            # æå–å½“å‰ 10ms å—
            start_idx = i * self._webrtc_frame_size
            end_idx = (i + 1) * self._webrtc_frame_size
            chunk = capture_audio[start_idx:end_idx]

            # å¤„ç†è¿™ä¸ª 10ms å—
            processed_chunk = self._process_single_frame(chunk)
            processed_chunks.append(processed_chunk)

        # å°†æ‰€æœ‰å¤„ç†åçš„å—é‡æ–°ç»„åˆ
        return np.concatenate(processed_chunks)

    def _get_reference_frame(self, frame_size: int) -> np.ndarray:
        """è·å–æŒ‡å®šå¤§å°çš„å‚è€ƒä¿¡å·å¸§
        
        ç­–ç•¥ï¼šä»ç¼“å†²åŒºå¤´éƒ¨æ¶ˆè€—å‚è€ƒä¿¡å·ï¼Œä¿æŒä¸éº¦å…‹é£é‡‡é›†çš„åŒæ­¥ã€‚
        å‚è€ƒä¿¡å·åº”è¯¥å…ˆäºéº¦å…‹é£ä¿¡å·é€å…¥ AECï¼ˆæ‰¬å£°å™¨æ’­æ”¾ â†’ ä¼ æ’­ â†’ éº¦å…‹é£å¬åˆ°ï¼‰ã€‚
        """
        # å¦‚æœæ²¡æœ‰å‚è€ƒä¿¡å·æˆ–ç¼“å†²åŒºä¸è¶³ï¼Œè¿”å›é™éŸ³
        if len(self._reference_buffer) < frame_size:
            if self._debug:
                print(f"âš ï¸ å‚è€ƒä¿¡å·ä¸è¶³: {len(self._reference_buffer)}/{frame_size}")
            self._stats['zero_reference_count'] += 1
            return np.zeros(frame_size, dtype=np.int16)

        # ä»ç¼“å†²åŒºå¤´éƒ¨æå–å¹¶æ¶ˆè€—ä¸€å¸§
        # è¿™æ ·å¯ä»¥ä¿æŒå‚è€ƒä¿¡å·å’Œé‡‡é›†ä¿¡å·çš„æ—¶åºå…³ç³»
        frame_data = []
        for _ in range(frame_size):
            if len(self._reference_buffer) > 0:
                frame_data.append(self._reference_buffer.popleft())
            else:
                frame_data.append(0)

        return np.array(frame_data, dtype=np.int16)

    def enable_debug(self, enable: bool = True):
        """å¯ç”¨æˆ–ç¦ç”¨è°ƒè¯•æ¨¡å¼"""
        self._debug = enable
        if enable:
            print("ğŸ› AEC è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
        else:
            print("âœ… AEC è°ƒè¯•æ¨¡å¼å·²ç¦ç”¨")
    
    def get_stats(self) -> dict:
        """è·å– AEC ç»Ÿè®¡ä¿¡æ¯"""
        return self._stats.copy()
    
    def print_stats(self):
        """æ‰“å° AEC ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("AEC ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        print(f"å·²å¤„ç†å¸§æ•°: {self._stats['frames_processed']}")
        print(f"å·²æ·»åŠ å‚è€ƒå¸§: {self._stats['reference_frames_added']}")
        print(f"é›¶å‚è€ƒè®¡æ•°: {self._stats['zero_reference_count']}")
        if self._stats['frames_processed'] > 0:
            zero_ratio = self._stats['zero_reference_count'] / self._stats['frames_processed'] * 100
            print(f"é›¶å‚è€ƒæ¯”ä¾‹: {zero_ratio:.1f}%")
            if zero_ratio > 50:
                print("âš ï¸  è­¦å‘Šï¼šè¶…è¿‡ 50% çš„å¸§æ²¡æœ‰å‚è€ƒä¿¡å·ï¼")
                print("   å¯èƒ½åŸå› ï¼šæ‰¬å£°å™¨éŸ³é‡å¤ªä½æˆ–æ²¡æœ‰æ’­æ”¾å£°éŸ³")
        print(f"ç¼“å†²åŒºå½“å‰å¤§å°: {len(self._reference_buffer)} samples")
        print("="*60 + "\n")

    def close(self):
        """å…³é—­ AEC å¤„ç†å™¨"""
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if self._stats['frames_processed'] > 0:
            self.print_stats()
        
        if self.apm:
            try:
                if self.capture_config:
                    self.apm.destroy_stream_config(self.capture_config)
                if self.render_config:
                    self.apm.destroy_stream_config(self.render_config)
            except Exception as e:
                print(f"âš ï¸ æ¸…ç† APM é…ç½®å¤±è´¥: {e}")
            finally:
                self.capture_config = None
                self.render_config = None
                self.apm = None

        self._reference_buffer.clear()
        self._is_initialized = False
        print("âœ… WebRTC AEC å·²å…³é—­")


# å…¼å®¹æ—§ä»£ç 
class SimpleAEC(WebRTCAECProcessor):
    """å…¼å®¹æ—§ä»£ç çš„åˆ«å"""
    pass
