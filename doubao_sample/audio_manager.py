import asyncio
import queue
import signal
import sys
import threading
import time
import uuid
import wave
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Dict, Any

import pyaudio

import config
from realtime_dialog_client import RealtimeDialogClient
from VikingMemory import VikingMemory, build_external_rag_payload
from utils import timer, normalize_messages, save_input_pcm_to_wav, save_output_to_file


@dataclass
class AudioConfig:
    """éŸ³é¢‘é…ç½®æ•°æ®ç±»"""
    format: str
    bit_size: int
    channels: int
    sample_rate: int
    chunk: int


class AudioDeviceManager:
    """éŸ³é¢‘è®¾å¤‡ç®¡ç†ç±»ï¼Œå¤„ç†éŸ³é¢‘è¾“å…¥è¾“å‡º"""

    def __init__(self, input_config: AudioConfig, output_config: AudioConfig):
        self.input_config = input_config
        self.output_config = output_config
        self.pyaudio = pyaudio.PyAudio()
        self.input_stream: Optional[pyaudio.Stream] = None
        self.output_stream: Optional[pyaudio.Stream] = None

    def open_input_stream(self) -> pyaudio.Stream:
        """æ‰“å¼€éŸ³é¢‘è¾“å…¥æµ"""
        self.input_stream = self.pyaudio.open(
            format=self.input_config.bit_size,
            channels=self.input_config.channels,
            rate=self.input_config.sample_rate,
            input=True,
            frames_per_buffer=self.input_config.chunk
        )
        return self.input_stream

    def open_output_stream(self) -> pyaudio.Stream:
        """æ‰“å¼€éŸ³é¢‘è¾“å‡ºæµ"""
        self.output_stream = self.pyaudio.open(
            format=self.output_config.bit_size,
            channels=self.output_config.channels,
            rate=self.output_config.sample_rate,
            output=True,
            frames_per_buffer=self.output_config.chunk
        )
        return self.output_stream

    def cleanup(self) -> None:
        """æ¸…ç†éŸ³é¢‘è®¾å¤‡èµ„æº"""
        for stream in [self.input_stream, self.output_stream]:
            if stream:
                stream.stop_stream()
                stream.close()
        self.pyaudio.terminate()


class DialogSession:
    """å¯¹è¯ä¼šè¯ç®¡ç†ç±»"""
    is_audio_file_input: bool
    mod: str

    def __init__(self, ws_config: Dict[str, Any], output_audio_format: str = "pcm", audio_file_path: str = "",
                 mod: str = "audio", recv_timeout: int = 10, use_memory: bool = False, use_aec: bool = False):
        self.use_memory = use_memory
        self.use_aec = use_aec
        self.aec_processor = None
        if self.use_memory:
            self.memory_client = VikingMemory()
            self.current_input = ""
            self.message_pairs = {}
            self.memory_injected = False
        self.audio_file_path = audio_file_path
        self.recv_timeout = recv_timeout
        self.is_audio_file_input = self.audio_file_path != ""
        if self.is_audio_file_input:
            mod = 'audio_file'
        else:
            self.say_hello_over_event = asyncio.Event()
        self.mod = mod

        self.session_id = str(uuid.uuid4())
        self.fallback_message_id = f"session:{self.session_id}"
        self.client = RealtimeDialogClient(config=ws_config, session_id=self.session_id,
                                           output_audio_format=output_audio_format, mod=mod, recv_timeout=recv_timeout)
        if output_audio_format == "pcm_s16le":
            config.output_audio_config["format"] = "pcm_s16le"
            config.output_audio_config["bit_size"] = pyaudio.paInt16

        self.is_running = True
        self.is_session_finished = False
        self.is_user_querying = False
        self.is_sending_tts_or_rag = False
        self.audio_buffer = b''

        signal.signal(signal.SIGINT, self._keyboard_signal)
        self.audio_queue = queue.Queue()
        if not self.is_audio_file_input:
            self.audio_device = AudioDeviceManager(
                AudioConfig(**config.input_audio_config),
                AudioConfig(**config.output_audio_config)
            )
            # åˆå§‹åŒ–éŸ³é¢‘é˜Ÿåˆ—å’Œè¾“å‡ºæµ
            self.output_stream = self.audio_device.open_output_stream()
            
            # åˆå§‹åŒ– AEC å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.use_aec:
                try:
                    from aec.aec_processor import WebRTCAECProcessor
                    self.aec_processor = WebRTCAECProcessor(
                        sample_rate=config.input_audio_config["sample_rate"]
                    )
                    if config.ENABLE_LOG:
                        print("âœ… AEC å¤„ç†å™¨å·²åˆå§‹åŒ–")
                except Exception as e:
                    if config.ENABLE_LOG:
                        print(f"âš ï¸ AEC åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.aec_processor = None
            
            # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            self.is_recording = True
            self.is_playing = True
            self.player_thread = threading.Thread(target=self._audio_player_thread)
            self.player_thread.daemon = True
            self.player_thread.start()

    def _audio_player_thread(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
        while self.is_playing:
            try:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
                audio_data = self.audio_queue.get(timeout=1.0)
                if audio_data is not None:
                    # å¦‚æœå¯ç”¨ AECï¼Œå°†æ’­æ”¾çš„éŸ³é¢‘ä½œä¸ºå‚è€ƒä¿¡å·
                    if self.use_aec and self.aec_processor:
                        try:
                            import numpy as np
                            
                            # æ ¹æ®è¾“å‡ºéŸ³é¢‘æ ¼å¼è½¬æ¢æ•°æ®
                            output_format = config.output_audio_config["bit_size"]
                            output_sample_rate = config.output_audio_config["sample_rate"]
                            input_sample_rate = config.input_audio_config["sample_rate"]
                            
                            if output_format == pyaudio.paFloat32:
                                # float32 æ ¼å¼ï¼šèŒƒå›´ [-1.0, 1.0]
                                audio_array = np.frombuffer(audio_data, dtype=np.float32)
                                # è½¬æ¢ä¸º int16ï¼šèŒƒå›´ [-32768, 32767]ï¼Œéœ€è¦ clip é˜²æ­¢æº¢å‡º
                                audio_array = np.clip(audio_array * 32768.0, -32768, 32767).astype(np.int16)
                            elif output_format == pyaudio.paInt16:
                                # int16 æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨
                                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                            else:
                                raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {output_format}")
                            
                            # å¦‚æœé‡‡æ ·ç‡ä¸åŒ¹é…ï¼Œéœ€è¦é‡é‡‡æ ·
                            if output_sample_rate != input_sample_rate:
                                # ç®€å•çš„é™é‡‡æ ·ï¼šæ¯éš” n ä¸ªæ ·æœ¬å–ä¸€ä¸ª
                                # 24000 -> 16000: å–æ ·æ¯”ä¾‹ = 16000/24000 = 2/3
                                downsample_ratio = input_sample_rate / output_sample_rate
                                indices = np.arange(0, len(audio_array), 1/downsample_ratio).astype(int)
                                audio_array = audio_array[indices[:int(len(audio_array) * downsample_ratio)]]
                            
                            self.aec_processor.add_reference(audio_array)
                        except Exception as e:
                            if config.ENABLE_LOG:
                                print(f"âš ï¸ AEC å‚è€ƒä¿¡å·æ·»åŠ å¤±è´¥: {e}")
                    
                    self.output_stream.write(audio_data)
            except queue.Empty:
                # é˜Ÿåˆ—ä¸ºç©ºæ—¶ç­‰å¾…ä¸€å°æ®µæ—¶é—´
                time.sleep(0.1)
            except Exception as e:
                if config.ENABLE_LOG:
                    print(f"éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")
                time.sleep(0.1)

    def handle_server_response(self, response: Dict[str, Any]) -> None:
        if response == {}:
            return
        """å¤„ç†æœåŠ¡å™¨å“åº”"""
        if response['message_type'] == 'SERVER_ACK' and isinstance(response.get('payload_msg'), bytes) and not self.is_sending_tts_or_rag:
            if config.ENABLE_LOG:
                print(f"\næ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(response['payload_msg'])} å­—èŠ‚")
            audio_data = response['payload_msg']
            if not self.is_audio_file_input:
                self.audio_queue.put(audio_data)
            self.audio_buffer += audio_data
        elif response['message_type'] == 'SERVER_FULL_RESPONSE':
            if config.ENABLE_LOG:
                print(f"æœåŠ¡å™¨å“åº”: {response}")
            event = response.get('event')
            payload_msg = response.get('payload_msg', {})

            if event == 450:
                if config.ENABLE_LOG:
                    print(f"æ¸…ç©ºç¼“å­˜éŸ³é¢‘: {response['session_id']}")
                while not self.audio_queue.empty():
                    try:
                        self.audio_queue.get_nowait()
                    except queue.Empty:
                        continue
                # æ‰“æ–­
                self.is_user_querying = True

            if event == 350:
                tts_type = payload_msg.get("tts_type")
                # åŸå§‹é—²èŠä¸åˆé€‚ï¼Œé»˜è®¤åªèµ°RAG
                if tts_type in ["default"] and self.is_sending_tts_or_rag:
                    while not self.audio_queue.empty():
                        try:
                            self.audio_queue.get_nowait()
                        except queue.Empty:
                            continue
                elif tts_type in ["external_rag", "chat_tts_text"]:
                    # å½“ä¸ºRAGå’ŒGTAçš„æ—¶å€™ï¼Œæ¥æ”¶éŸ³é¢‘
                    self.is_sending_tts_or_rag = False
                    if self.use_memory:
                        reply_id = payload_msg.get("reply_id")
                        if reply_id:
                            self.message_pairs[reply_id] = {
                                "user": self.current_input,
                                "assistant": ""
                            }

            if event == 451 and self.use_memory:
                results = payload_msg.get("results", [])
                extra = payload_msg.get("extra")
                if "endpoint" not in extra or bool(extra["endpoint"]) != True:
                    return
                # ç”¨æˆ·è¯´å®Œè¯äº†ï¼Œé»˜è®¤åŠ å…¥RAGï¼Œä¸”ä¸æ¥æ”¶defaultéŸ³é¢‘
                self.current_input = results[0]["text"]
                print(f"current inputcurrent input: {self.current_input}")
                self.is_sending_tts_or_rag = True
                asyncio.create_task(self.trigger_rag_for_query(self.current_input))

            if event == 459:
                # è§£é™¤æ‰“æ–­
                self.is_user_querying = False

            if event == 553 and self.use_memory:
                self.is_sending_tts_or_rag = True
                asyncio.create_task(self.trigger_rag_for_query(self.current_input))

            if event == 550 and self.use_memory:
                content = payload_msg.get("content")
                reply_id = payload_msg.get("reply_id")
                if content and reply_id in self.message_pairs:
                    self.message_pairs[reply_id]["assistant"] += content
                

        elif response['message_type'] == 'SERVER_ERROR':
            if config.ENABLE_LOG:
                print(f"æœåŠ¡å™¨é”™è¯¯: {response['payload_msg']}")
            raise Exception("æœåŠ¡å™¨é”™è¯¯")

    # async def trigger_chat_tts_text(self):
    #     """æ¦‚ç‡è§¦å‘å‘é€ChatTTSTextè¯·æ±‚"""
    #     if config.ENABLE_LOG:
    #         print("hit ChatTTSText event, start sending...")
    #     await self.client.chat_tts_text(
    #         is_user_querying=self.is_user_querying,
    #         start=True,
    #         end=False,
    #         content="emmm",
    #     )
    #     await self.client.chat_tts_text(
    #         is_user_querying=self.is_user_querying,
    #         start=False,
    #         end=True,
    #         content="",
    #     )

    # async def trigger_chat_rag_text(self):
    #     await asyncio.sleep(0) # æ¨¡æ‹ŸæŸ¥è¯¢å¤–éƒ¨RAGçš„è€—æ—¶ï¼Œè¿™é‡Œä¸ºäº†ä¸å½±å“GTAå®‰æŠšè¯æœ¯çš„æ’­æŠ¥ï¼Œç›´æ¥sleep 5ç§’
    #     if config.ENABLE_LOG:
    #         print("hit ChatRAGText event, start sending...")
    #     await self.client.chat_rag_text(self.is_user_querying, external_rag='[{"title":"åŒ—äº¬å¤©æ°”","content":"ä»Šå¤©åŒ—äº¬æ•´ä½“ä»¥æ™´åˆ°å¤šäº‘ä¸ºä¸»ï¼Œä½†è¥¿éƒ¨å’ŒåŒ—éƒ¨åœ°å¸¦å¯èƒ½ä¼šå‡ºç°åˆ†æ•£æ€§é›·é˜µé›¨ï¼Œç‰¹åˆ«æ˜¯åˆåè‡³å‚æ™šæ—¶æ®µéœ€æ³¨æ„çªå‘é™é›¨ã€‚\nğŸ’¨ é£å†µä¸æ¹¿åº¦\né£åŠ›è¾ƒå¼±ï¼Œä¸€èˆ¬ä¸º 2â€“3 çº§å—é£æˆ–è¥¿å—é£\nç™½å¤©æ¹¿åº¦è¾ƒé«˜ï¼Œæ—©æ™šç•¥å‡‰çˆ½"}]')

    async def inject_memory_once(self) -> None:
        if not self.use_memory or self.memory_injected:
            return
        try:
            profile = await self.memory_client.search_profile()
            recent_events = await self.memory_client.search_recent_events(1, 2)
            memory_summary = (
                "å·²çŸ¥ç”¨æˆ·ç”»åƒä¸è¿‘æœŸäº‹ä»¶ï¼ˆä»…ç”¨äºå¯¹è¯å‚è€ƒï¼‰ï¼š\n"
                f"Profile: {profile}\n"
                f"RecentEvents: {recent_events}"
            )
            items = [
                {"role": "user", "text": "è®°å¿†æ‘˜è¦"},
                {"role": "assistant", "text": memory_summary},
            ]
            await self.client.conversation_create(items)
            self.memory_injected = True
        except Exception as e:
            if config.ENABLE_LOG:
                print(f"memory inject error: {e}")

    async def trigger_rag_for_query(self, query: str) -> None:
        if not self.use_memory:
            return
        external_rag = await build_external_rag_payload(
            memory_client=self.memory_client,
            query=query,
            max_items=2,
        )
        if external_rag and external_rag != "[]":
            await self.client.chat_rag_text(self.is_user_querying, external_rag)

    async def receive_loop(self):
        try:
            while True:
                response = await self.client.receive_server_response()
                self.handle_server_response(response)
                if 'event' in response and (response['event'] == 152 or response['event'] == 153):
                    if config.ENABLE_LOG:
                        print(f"receive session finished event: {response['event']}")
                    self.is_session_finished = True
                    break
                if 'event' in response and response['event'] == 359:
                    if self.is_audio_file_input:
                        if config.ENABLE_LOG:
                            print(f"receive tts ended event")
                        self.is_session_finished = True
                        break
                    else:
                        if not self.say_hello_over_event.is_set():
                            if config.ENABLE_LOG:
                                print(f"SayHello over, input loop start...")
                            self.say_hello_over_event.set()
                        if self.mod == "text":
                            if config.ENABLE_LOG:
                                print("è¯·è¾“å…¥å†…å®¹ï¼š")

        except asyncio.CancelledError:
            if config.ENABLE_LOG:
                print("æ¥æ”¶ä»»åŠ¡å·²å–æ¶ˆ")
        except Exception as e:
            if config.ENABLE_LOG:
                print(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")
        finally:
            self.stop()
            self.is_session_finished = True

    async def process_text_input(self) -> None:
        await self.client.say_hello()
        await self.say_hello_over_event.wait()
        """ä¸»é€»è¾‘ï¼šå¤„ç†æ–‡æœ¬è¾“å…¥å’ŒWebSocketé€šä¿¡"""
        # ç¡®ä¿è¿æ¥æœ€ç»ˆå…³é—­
        try:
            # å¯åŠ¨è¾“å…¥ç›‘å¬çº¿ç¨‹
            input_queue = queue.Queue()
            input_thread = threading.Thread(target=self.input_listener, args=(input_queue,), daemon=True)
            input_thread.start()
            # ä¸»å¾ªç¯ï¼šå¤„ç†è¾“å…¥å’Œä¸Šä¸‹æ–‡ç»“æŸ
            while self.is_running:
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥ï¼ˆéé˜»å¡ï¼‰
                    input_str = input_queue.get_nowait()
                    if input_str is None:
                        # è¾“å…¥æµå…³é—­
                        if config.ENABLE_LOG:
                            print("Input channel closed")
                        break
                    if input_str:
                        if self.use_memory:
                            self.current_input = input_str
                        # å‘é€è¾“å…¥å†…å®¹
                        await self.client.chat_text_query(input_str)
                except queue.Empty:
                    # æ— è¾“å…¥æ—¶çŸ­æš‚ä¼‘çœ 
                    await asyncio.sleep(0.1)
                except Exception as e:
                    if config.ENABLE_LOG:
                        print(f"Main loop error: {e}")
                    break
        finally:
            if config.ENABLE_LOG:
                print("exit text input")

    def input_listener(self, input_queue: queue.Queue) -> None:
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­ç›‘å¬æ ‡å‡†è¾“å…¥"""
        try:
            while True:
                # è¯»å–æ ‡å‡†è¾“å…¥ï¼ˆé˜»å¡æ“ä½œï¼‰
                line = sys.stdin.readline()
                if not line:
                    # è¾“å…¥æµå…³é—­
                    input_queue.put(None)
                    break
                input_str = line.strip()
                input_queue.put(input_str)
        except Exception as e:
            if config.ENABLE_LOG:
                print(f"Input listener error: {e}")
            input_queue.put(None)

    def _keyboard_signal(self, sig, frame):
        if config.ENABLE_LOG:
            print(f"receive keyboard Ctrl+C")
        self.stop()

    async def process_microphone_input(self) -> None:
        timer.start("process_microphone")
        await self.client.say_hello()
        await self.say_hello_over_event.wait()

        """å¤„ç†éº¦å…‹é£è¾“å…¥"""
        stream = self.audio_device.open_input_stream()
        if config.ENABLE_LOG:
            print("å·²æ‰“å¼€éº¦å…‹é£ï¼Œè¯·è®²è¯...")

        while self.is_recording:
            try:
                # æ·»åŠ exception_on_overflow=Falseå‚æ•°æ¥å¿½ç•¥æº¢å‡ºé”™è¯¯
                audio_data = stream.read(config.input_audio_config["chunk"], exception_on_overflow=False)
                
                # å¦‚æœå¯ç”¨ AECï¼Œå¯¹éº¦å…‹é£è¾“å…¥è¿›è¡Œå¤„ç†
                if self.use_aec and self.aec_processor:
                    try:
                        import numpy as np
                        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º numpy æ•°ç»„ï¼ˆè¾“å…¥æ˜¯ int16 æ ¼å¼ï¼‰
                        input_format = config.input_audio_config["bit_size"]
                        if input_format == pyaudio.paInt16:
                            audio_array = np.frombuffer(audio_data, dtype=np.int16)
                            # åº”ç”¨ AEC å¤„ç†
                            processed_array = self.aec_processor.process(audio_array)
                            # è½¬æ¢å› bytes
                            audio_data = processed_array.tobytes()
                        else:
                            if config.ENABLE_LOG:
                                print(f"âš ï¸ AEC ä»…æ”¯æŒ int16 è¾“å…¥æ ¼å¼ï¼Œå½“å‰æ ¼å¼: {input_format}")
                    except Exception as e:
                        if config.ENABLE_LOG:
                            print(f"âš ï¸ AEC å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘: {e}")
                
                data_dir = Path(__file__).resolve().parent / "data"
                data_dir.mkdir(parents=True, exist_ok=True)
                save_input_pcm_to_wav(audio_data, str(data_dir / "input.pcm"))
                await self.client.task_request(audio_data)
                await asyncio.sleep(0.01)  # é¿å…CPUè¿‡åº¦ä½¿ç”¨
            except Exception as e:
                if config.ENABLE_LOG:
                    print(f"è¯»å–éº¦å…‹é£æ•°æ®å‡ºé”™: {e}")
                await asyncio.sleep(0.1)  # ç»™ç³»ç»Ÿä¸€äº›æ¢å¤æ—¶é—´
        timer.end("process_microphone")

    async def process_audio_file_input(self, audio_file_path: str) -> None:
        timer.start("process_audio_file")
        # è¯»å–WAVæ–‡ä»¶
        with wave.open(audio_file_path, 'rb') as wf:
            chunk_size = config.input_audio_config["chunk"]
            framerate = wf.getframerate()  # é‡‡æ ·ç‡ï¼ˆå¦‚16000Hzï¼‰
            # æ—¶é•¿ = chunkSizeï¼ˆå¸§æ•°ï¼‰ Ã· é‡‡æ ·ç‡ï¼ˆå¸§/ç§’ï¼‰
            sleep_seconds = chunk_size / framerate
            if config.ENABLE_LOG:
                print(f"å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_file_path}")

            # åˆ†å—è¯»å–å¹¶å‘é€éŸ³é¢‘æ•°æ®
            while True:
                audio_data = wf.readframes(chunk_size)
                if not audio_data:
                    break  # æ–‡ä»¶è¯»å–å®Œæ¯•

                await self.client.task_request(audio_data)
                # sleepä¸chunkå¯¹åº”çš„éŸ³é¢‘æ—¶é•¿ä¸€è‡´ï¼Œæ¨¡æ‹Ÿå®æ—¶è¾“å…¥
                await asyncio.sleep(sleep_seconds)

            if config.ENABLE_LOG:
                print(f"éŸ³é¢‘æ–‡ä»¶å¤„ç†å®Œæˆï¼Œç­‰å¾…æœåŠ¡å™¨å“åº”...")
        timer.end("process_audio_file")

    async def process_silence_audio(self) -> None:
        """å‘é€é™éŸ³éŸ³é¢‘"""
        silence_data = b'\x00' * 320
        await self.client.task_request(silence_data)

    async def start(self) -> None:
        """å¯åŠ¨å¯¹è¯ä¼šè¯"""
        timer.start("session_start")
        try:
            await self.client.connect()

            if self.use_memory:
                await self.inject_memory_once()

            if self.mod == "text":
                asyncio.create_task(self.process_text_input())
                asyncio.create_task(self.receive_loop())
                while self.is_running:
                    await asyncio.sleep(0.1)
            else:
                if self.is_audio_file_input:
                    asyncio.create_task(self.process_audio_file_input(self.audio_file_path))
                    await self.receive_loop()
                else:
                    asyncio.create_task(self.process_microphone_input())
                    asyncio.create_task(self.receive_loop())
                    while self.is_running:
                        await asyncio.sleep(0.1)

            if self.use_memory:
                # import pprint
                # print()
                # pprint.pprint(self.message_pairs, indent=4)
                # print()
                nms = normalize_messages(self.message_pairs)
                if config.ENABLE_LOG:
                    print(f"Upload Messages for memory length: {len(nms)}")
                    print(f"Upload Message Contents: {nms}")
                await self.memory_client.save_memory(self.session_id, messages=nms)

            await self.client.finish_session()
            while not self.is_session_finished:
                await asyncio.sleep(0.1)
            await self.client.finish_connection()
            await asyncio.sleep(0.1)
            await self.client.close()
            if config.ENABLE_LOG:
                print(f"dialog request logid: {self.client.logid}, chat mod: {self.mod}")
            data_dir = Path(__file__).resolve().parent / "data"
            data_dir.mkdir(parents=True, exist_ok=True)
            save_output_to_file(self.audio_buffer, str(data_dir / "output.pcm"))
        except Exception as e:
            if config.ENABLE_LOG:
                print(f"ä¼šè¯é”™è¯¯: {e}")
            self.stop()
            await asyncio.sleep(1)
            sys.exit(1)
        finally:
            if not self.is_audio_file_input:
                self.audio_device.cleanup()
            timer.end("session_start")
            # æ‰“å°è®¡æ—¶æ‘˜è¦
            timer.print_summary()

    def stop(self):
        self.is_recording = False
        self.is_playing = False
        self.is_running = False