"""
ASR é›†æˆç¤ºä¾‹ - å°†è¯­éŸ³è¯†åˆ«é›†æˆåˆ°ä¸»ç¨‹åº
æ”¯æŒ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰åŠŸèƒ½
"""
import os
import sys
import time
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.asr import DashScopeASR, AudioInput, InterruptController
from src.asr.aec_processor import SimpleAEC
from src.main import LLMTTSTest
from src.role_loader import RoleLoader


def load_env_file():
    """æ‰‹åŠ¨åŠ è½½ .env æ–‡ä»¶"""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    env_vars = {}
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    return env_vars


class VoiceInteractiveMode:
    """è¯­éŸ³äº¤äº’æ¨¡å¼ - æ”¯æŒè¯­éŸ³è¾“å…¥å’Œæ‰“æ–­ï¼Œé›†æˆ AEC å›å£°æ¶ˆé™¤"""

    def __init__(self, enable_aec: bool = True, use_aggregate_device: bool = False, device_index: Optional[int] = None):
        """
        åˆå§‹åŒ–è¯­éŸ³äº¤äº’æ¨¡å¼

        Args:
            enable_aec: æ˜¯å¦å¯ç”¨ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰
            use_aggregate_device: æ˜¯å¦ä½¿ç”¨èšåˆè®¾å¤‡ï¼ˆç¡¬ä»¶ AECï¼‰
            device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ˆèšåˆè®¾å¤‡çš„ç´¢å¼•ï¼‰
        """
        # åŠ è½½ç¯å¢ƒå˜é‡
        env_vars = load_env_file()
        api_key = env_vars.get('QWEN3_API_KEY') or os.getenv('QWEN3_API_KEY')

        if not api_key:
            raise ValueError('æœªæ‰¾åˆ° QWEN3_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶')

        # åŠ è½½è§’è‰²é…ç½®
        role_loader = RoleLoader()
        role_config = role_loader.get_role("xuejie")  # ä½¿ç”¨å­¦å§åŠ©æ‰‹è§’è‰²

        # åˆå§‹åŒ–ä¸»ç¨‹åº
        self.llm_tts = LLMTTSTest(role_config=role_config)
        self.llm_tts.initialize_llm()

        # åˆå§‹åŒ– ASR
        self.asr = DashScopeASR(api_key=api_key)

        # åˆå§‹åŒ– AEC å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.enable_aec = enable_aec
        self.use_aggregate_device = use_aggregate_device
        self.aec_processor = None

        if enable_aec:
            try:
                self.aec_processor = SimpleAEC(sample_rate=16000)
                if use_aggregate_device:
                    print("ğŸ›ï¸ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰å·²å¯ç”¨ - ç¡¬ä»¶æ¨¡å¼ï¼ˆèšåˆè®¾å¤‡ï¼‰")
                else:
                    print("ğŸ›ï¸ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰å·²å¯ç”¨ - è½¯ä»¶æ¨¡å¼ï¼ˆä¸æ¨èï¼Œå¯èƒ½ä¸ç¨³å®šï¼‰")
            except Exception as e:
                print(f"âš ï¸ AEC åˆå§‹åŒ–å¤±è´¥: {e}")
                print("   å°†ç»§ç»­è¿è¡Œä½†ä¸ä½¿ç”¨ AEC")
                self.enable_aec = False

        # åˆå§‹åŒ–éŸ³é¢‘è¾“å…¥ï¼ˆä¼ å…¥ AEC å¤„ç†å™¨å’Œèšåˆè®¾å¤‡é…ç½®ï¼‰
        self.audio_input = AudioInput(
            sample_rate=16000,
            chunk_size=1600,
            enable_aec=self.enable_aec,
            aec_processor=self.aec_processor,
            use_aggregate_device=use_aggregate_device,
            device_index=device_index
        )

        # åˆå§‹åŒ–æ‰“æ–­æ§åˆ¶å™¨
        self.interrupt_controller = InterruptController()

        # åˆå§‹åŒ– TTS å®¢æˆ·ç«¯ï¼ˆå…¨å±€å¤ç”¨ï¼Œåˆå§‹åŒ–æ—¶åˆ›å»ºä¸€æ¬¡ï¼‰
        from src.tts.volcengine_realtime_tts import VolcengineRealtimeTTS
        config = self.llm_tts.config.get("volcengine_seed2", {})
        self.realtime_tts = VolcengineRealtimeTTS(
            app_id=config.get("app_id"),
            access_token=config.get("access_token") or config.get("api_key"),
            voice="zh_female_cancan_mars_bigtts"
        )

        # çŠ¶æ€
        self.is_listening = False
        self.is_tts_playing = False
        self.current_text = ""
        self.current_pipeline = None  # å½“å‰æ­£åœ¨è¿è¡Œçš„ pipeline
        self.current_player = None    # å½“å‰æ­£åœ¨æ’­æ”¾çš„ player
        self.current_tts_thread = None  # å½“å‰ TTS çº¿ç¨‹
        self.last_sentence_time = 0  # ä¸Šæ¬¡è§¦å‘å¯¹è¯çš„æ—¶é—´ï¼ˆé˜²æ­¢å¤ªå¿«é‡å¤è§¦å‘ï¼‰

    def on_asr_text(self, text: str):
        """ASR ä¸­é—´ç»“æœå›è°ƒ"""
        # å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œåªç”¨äºæ‰“æ–­æ£€æµ‹ï¼Œä¸æ˜¾ç¤º
        if self.is_tts_playing:
            self.interrupt_controller.on_asr_text(text, is_final=False)
            return

        self.current_text = text
        print(f'\rğŸ’¬ {text}', end='', flush=True)

    def on_asr_sentence(self, text: str):
        """ASR å®Œæ•´å¥å­å›è°ƒ"""
        # è¿‡æ»¤ç©ºæ–‡æœ¬å’Œå¤ªçŸ­çš„æ–‡æœ¬ï¼ˆé¿å…å™ªéŸ³è§¦å‘ï¼‰
        if not text or not text.strip() or len(text.strip()) < 2:
            return

        # å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®æ‰“æ–­
        # æé«˜é˜ˆå€¼ï¼šåªæœ‰å½“è¯†åˆ«çš„æ–‡æœ¬è¶³å¤Ÿé•¿ï¼ˆ> 8 ä¸ªå­—ç¬¦ï¼‰æ—¶æ‰è®¤ä¸ºæ˜¯çœŸå®æ‰“æ–­
        if self.is_tts_playing:
            text_length = len(text.strip())
            if text_length < 8:
                print(f'\nâš ï¸ å¿½ç•¥çŸ­æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å›å£°ï¼‰: "{text}" (é•¿åº¦: {text_length})')
                return
            else:
                # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœæ–‡æœ¬åŒ…å«å¸¸è§çš„å›å£°è¯ï¼Œä¹Ÿå¿½ç•¥
                echo_keywords = ['å—¯', 'å•Š', 'å“¦', 'å‘ƒ', 'è¡Œ', 'å¥½', 'æ˜¯', 'ä¸æ˜¯', 'å¯¹', 'æ²¡']
                if any(keyword == text.strip() for keyword in echo_keywords):
                    print(f'\nâš ï¸ å¿½ç•¥å›å£°å…³é”®è¯: "{text}"')
                    return
                print(f'\nğŸ”” æ£€æµ‹åˆ°æ‰“æ–­: "{text}" (é•¿åº¦: {text_length})')

        # é˜²æ­¢è¯´è¯å¤ªå¿«æ—¶é‡å¤è§¦å‘ï¼ˆé—´éš”å°‘äº1ç§’çš„å¿½ç•¥ï¼‰
        current_time = time.time()
        if current_time - self.last_sentence_time < 1.0 and not self.is_tts_playing:
            return
        self.last_sentence_time = current_time

        # å¦‚æœæ­£åœ¨æ’­æ”¾ï¼Œç›´æ¥æ‰“æ–­å¹¶æ¸…ç©ºï¼ˆä¸ç­‰å¾…ï¼‰
        if self.is_tts_playing:
            self.on_interrupt()
            # ä¸ç­‰å¾…æ—§çº¿ç¨‹ï¼Œç›´æ¥ç»§ç»­ï¼ˆæ‰“æ–­å°±æ˜¯æ‰“æ–­ï¼Œä¸ç®¡æ—§çš„äº†ï¼‰

        print(f'\n\nğŸ‘¤ ä½ : {text}')
        self.current_text = ""

        # åœæ­¢ç›‘å¬
        self.is_listening = False

        # åœ¨æ–°çº¿ç¨‹ä¸­å¤„ç† LLM + TTSï¼Œé¿å…é˜»å¡ ASR
        import threading
        tts_thread = threading.Thread(target=self._process_and_speak, args=(text,))
        tts_thread.daemon = True
        tts_thread.start()
        self.current_tts_thread = tts_thread

    def _process_and_speak(self, text: str):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¤„ç† LLM + TTS"""
        try:
            # å‘é€ç»™ LLM å¹¶æ’­æ”¾å›å¤
            self.is_tts_playing = True

            # å¯åŠ¨æ‰“æ–­ç›‘å¬ï¼ˆåœ¨ TTS æ’­æ”¾æ—¶ï¼‰
            self.interrupt_controller.set_tts_speaking(True)

            # è·å– LLM æ¶ˆæ¯
            messages = self.llm_tts.voice_prompt.get_messages(text, user_id=self.llm_tts.user_id)

            # å¤ç”¨å…¨å±€ TTS å®¢æˆ·ç«¯ï¼ˆä¸å†æ¯æ¬¡åˆ›å»ºæ–°çš„ï¼‰
            from src.audio.pyaudio_player import PyAudioStreamPlayer
            from src.realtime_pipeline import RealtimeStreamingPipeline
            import numpy as np

            # åˆ›å»ºå‚è€ƒéŸ³é¢‘å›è°ƒï¼ˆç”¨äº AECï¼‰
            def reference_callback(audio_data: bytes):
                """å°†æ’­æ”¾çš„éŸ³é¢‘ä½œä¸ºå‚è€ƒä¿¡å·ä¼ é€’ç»™ AEC"""
                if self.enable_aec and self.audio_input:
                    try:
                        # TTS è¾“å‡ºæ˜¯ 24kHzï¼Œéœ€è¦é‡é‡‡æ ·åˆ° 16kHz
                        audio_array = np.frombuffer(audio_data, dtype=np.int16)

                        # ä½¿ç”¨ scipy è¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        try:
                            from scipy import signal as scipy_signal
                            # 24000 -> 16000 çš„é‡é‡‡æ ·
                            num_samples = int(len(audio_array) * 16000 / 24000)
                            resampled = scipy_signal.resample(audio_array, num_samples).astype(np.int16)
                        except ImportError:
                            # å¦‚æœæ²¡æœ‰ scipyï¼Œä½¿ç”¨ç®€å•çš„é™é‡‡æ ·
                            # 24000 -> 16000 (3:2)
                            if len(audio_array) >= 3:
                                indices = np.arange(0, len(audio_array), 1.5).astype(int)
                                indices = indices[indices < len(audio_array)]
                                resampled = audio_array[indices]
                            else:
                                resampled = audio_array

                        # æ·»åŠ åˆ° AEC å‚è€ƒä¿¡å·
                        self.audio_input.add_reference_audio(resampled.tobytes())

                        # è°ƒè¯•ï¼šæ¯ 50 æ¬¡æ‰“å°ä¸€æ¬¡
                        if not hasattr(self, '_ref_counter'):
                            self._ref_counter = 0
                        self._ref_counter += 1
                        if self._ref_counter % 50 == 0:
                            ref_rms = np.sqrt(np.mean(resampled.astype(np.float32) ** 2))
                            print(f"[AEC] å‚è€ƒä¿¡å·: {len(resampled)} æ ·æœ¬, RMS={ref_rms:.1f}")

                    except Exception as e:
                        print(f"[AEC] å‚è€ƒä¿¡å·å¤„ç†é”™è¯¯: {e}")

            # åˆ›å»ºæµå¼æ’­æ”¾å™¨ï¼ˆæ¯æ¬¡åˆ›å»ºæ–°çš„ï¼Œé¿å…çŠ¶æ€å†²çªï¼‰
            streaming_player = PyAudioStreamPlayer(
                sample_rate=24000,
                reference_callback=reference_callback if self.enable_aec else None
            )

            # åˆ›å»ºå®æ—¶ç®¡é“
            pipeline = RealtimeStreamingPipeline()

            # ä¿å­˜å¼•ç”¨ä»¥ä¾¿æ‰“æ–­
            self.current_pipeline = pipeline
            self.current_player = streaming_player

            # è·å– LLM æµå¼è¾“å‡º
            llm_stream = self.llm_tts.llm_client.chat_stream(
                messages=messages,
                temperature=self.llm_tts.test_config["llm_config"]["temperature"]
            )

            # è¿è¡Œå®æ—¶ç®¡é“ï¼ˆå¤ç”¨å…¨å±€ TTS å®¢æˆ·ç«¯ï¼‰
            result = pipeline.run(
                llm_stream=llm_stream,
                realtime_tts_client=self.realtime_tts,
                streaming_player=streaming_player,
                display_text=True
            )

            # ä¿å­˜å¯¹è¯å†å²ï¼ˆå³ä½¿è¢«æ‰“æ–­ä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸º LLM å·²ç»ç”Ÿæˆäº†å›å¤ï¼‰
            if result and result.get("text"):
                self.llm_tts.voice_prompt.add_conversation('user', text)
                self.llm_tts.voice_prompt.add_conversation('assistant', result["text"])

                # ä¿å­˜åˆ° Mem0ï¼ˆå³ä½¿è¢«æ‰“æ–­ä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸ºå¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
                if self.llm_tts.mem0_manager:
                    self.llm_tts.mem0_manager.add_conversation(
                        user_input=text,
                        assistant_response=result["text"],
                        user_id=self.llm_tts.user_id
                    )

        except Exception as e:
            print(f'\nâŒ é”™è¯¯: {e}')

        finally:
            # æ¸…é™¤å¼•ç”¨
            self.current_pipeline = None
            self.current_player = None

            # TTS æ’­æ”¾å®Œæˆ
            self.is_tts_playing = False
            self.interrupt_controller.set_tts_speaking(False)

            # é‡æ–°å¼€å§‹ç›‘å¬
            self.is_listening = True
            print('\n')

    def on_interrupt(self):
        """æ‰“æ–­å›è°ƒ"""
        # åœæ­¢ TTS ç®¡é“
        if self.current_pipeline:
            self.current_pipeline.stop()

        # ç«‹å³ç»“æŸæ—§ sessionï¼ˆç«å±±å¼•æ“é™åˆ¶åŒæ—¶åªèƒ½æœ‰1ä¸ªsessionï¼‰
        if hasattr(self, 'realtime_tts'):
            self.realtime_tts.finish()
            self.realtime_tts.clear_queue()

        # åœæ­¢éŸ³é¢‘æ’­æ”¾
        if self.current_player:
            self.current_player.stop()

        self.is_tts_playing = False

    def start(self):
        """å¯åŠ¨è¯­éŸ³äº¤äº’"""
        print('\nğŸ™ï¸  å¯¼å¸ˆè¯„ä»·å­¦å§åŠ©æ‰‹ - è¯­éŸ³äº¤äº’æ¨¡å¼')
        if self.enable_aec:
            print('ğŸ›ï¸  AEC å›å£°æ¶ˆé™¤å·²å¯ç”¨')
        print('â”' * 50)
        print('æŒ‰ Ctrl+C é€€å‡º\n')

        try:
            # å¯åŠ¨éŸ³é¢‘è¾“å…¥ï¼ˆå…ˆå¯åŠ¨ï¼Œç¡®ä¿éº¦å…‹é£æ‰“å¼€ï¼‰
            self.audio_input.start(audio_callback=self.asr.send_audio)

            # å¯åŠ¨ ASRï¼ˆåœ¨åå°ï¼‰
            import threading
            asr_thread = threading.Thread(
                target=self.asr.start,
                kwargs={
                    'on_text': self.on_asr_text,
                    'on_sentence': self.on_asr_sentence
                },
                daemon=True
            )
            asr_thread.start()
            time.sleep(0.5)

            # å¯åŠ¨æ‰“æ–­æ§åˆ¶å™¨
            self.interrupt_controller.start_monitoring(
                interrupt_callback=self.on_interrupt
            )

            self.is_listening = True
            print('ğŸ¤ è¯·è¯´è¯...\n')

            # æŒç»­è¿è¡Œ
            while True:
                time.sleep(0.1)

        except KeyboardInterrupt:
            print('\n\nğŸ‘‹ å†è§!')

        finally:
            # æ¸…ç†èµ„æº
            self.audio_input.stop()
            self.asr.stop()
            self.audio_input.close()
            self.interrupt_controller.stop_monitoring()

            # å…³é—­ AEC å¤„ç†å™¨
            if self.aec_processor:
                self.aec_processor.close()

            # æ–­å¼€ TTS è¿æ¥ï¼ˆå¤ç”¨çš„å…¨å±€å®¢æˆ·ç«¯ï¼‰
            if hasattr(self, 'realtime_tts'):
                self.realtime_tts.disconnect()


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='è¯­éŸ³äº¤äº’æ¨¡å¼ - æ”¯æŒ AEC å›å£°æ¶ˆé™¤')
    parser.add_argument('--no-aec', action='store_true', help='ç¦ç”¨ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰')
    parser.add_argument('--use-aggregate', action='store_true', help='ä½¿ç”¨èšåˆè®¾å¤‡ï¼ˆç¡¬ä»¶ AECï¼Œæ¨èï¼‰')
    parser.add_argument('--device-index', type=int, help='éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ˆèšåˆè®¾å¤‡çš„ç´¢å¼•ï¼‰')
    parser.add_argument('--list-devices', action='store_true', help='åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡')
    args = parser.parse_args()

    # å¦‚æœç”¨æˆ·è¦æ±‚åˆ—å‡ºè®¾å¤‡
    if args.list_devices:
        import pyaudio
        p = pyaudio.PyAudio()
        print("\nå¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼š")
        print("=" * 80)
        for i in range(p.get_device_count()):
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                print(f"\nè®¾å¤‡ {i}: {info['name']}")
                print(f"  è¾“å…¥é€šé“æ•°: {info['maxInputChannels']}")
                print(f"  é‡‡æ ·ç‡: {int(info['defaultSampleRate'])} Hz")
                if 'Aggregate' in info['name']:
                    print("  â­ è¿™æ˜¯èšåˆè®¾å¤‡ï¼")
        print("=" * 80)
        p.terminate()
        return

    # æ£€æŸ¥å‚æ•°
    if args.use_aggregate and args.device_index is None:
        print("âŒ é”™è¯¯ï¼šä½¿ç”¨ --use-aggregate æ—¶å¿…é¡»æŒ‡å®š --device-index")
        print("   è¯·å…ˆè¿è¡Œ python list_audio_devices.py æŸ¥çœ‹è®¾å¤‡ç´¢å¼•")
        return

    try:
        voice_mode = VoiceInteractiveMode(
            enable_aec=not args.no_aec,
            use_aggregate_device=args.use_aggregate,
            device_index=args.device_index
        )
        voice_mode.start()
    except Exception as e:
        print(f'é”™è¯¯: {e}')
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
