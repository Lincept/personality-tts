"""
ASR é›†æˆç¤ºä¾‹ - å°†è¯­éŸ³è¯†åˆ«é›†æˆåˆ°ä¸»ç¨‹åº
æ”¯æŒ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰åŠŸèƒ½
"""
import os
import sys
import time
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.asr import DashScopeASR, AudioInput, InterruptController
from src.asr.aec_processor import SimpleAEC
from src.main import LLMTTSTest
from src.role_loader import RoleLoader


def load_env_file():
    """æ‰‹åŠ¨åŠ è½½ .env æ–‡ä»¶"""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    env_vars = {}
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    return env_vars


class VoiceInteractiveMode:
    """è¯­éŸ³äº¤äº’æ¨¡å¼ - æ”¯æŒè¯­éŸ³è¾“å…¥å’Œæ‰“æ–­ï¼Œé›†æˆ AEC å›å£°æ¶ˆé™¤"""

    def __init__(self, enable_aec: bool = True, device_index: Optional[int] = None, asr_model: str = "paraformer-realtime-v2"):
        """
        åˆå§‹åŒ–è¯­éŸ³äº¤äº’æ¨¡å¼

        Args:
            enable_aec: æ˜¯å¦å¯ç”¨ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰- éœ€è¦é…ç½®èšåˆè®¾å¤‡
            device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ˆèšåˆè®¾å¤‡çš„ç´¢å¼•ï¼Œå¯ç”¨ AEC æ—¶å¿…é¡»æä¾›ï¼‰
            asr_model: ASR æ¨¡å‹é€‰æ‹©
                - "paraformer-realtime-v2": Paraformer å®æ—¶æ¨¡å‹ v2ï¼ˆæ¨èï¼Œå‡†ç¡®åº¦é«˜ï¼‰
                - "fun-asr-realtime-2025-11-07": FunASR 2025 ç‰ˆæœ¬ï¼ˆé»˜è®¤ï¼‰
        """
        # åŠ è½½ç¯å¢ƒå˜é‡
        env_vars = load_env_file()
        api_key = env_vars.get('QWEN3_API_KEY') or os.getenv('QWEN3_API_KEY')

        if not api_key:
            raise ValueError('æœªæ‰¾åˆ° QWEN3_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶')

        # åŠ è½½è§’è‰²é…ç½®
        role_loader = RoleLoader()
        role_config = role_loader.get_role("xuejie")  # ä½¿ç”¨å­¦å§åŠ©æ‰‹è§’è‰²

        # åˆå§‹åŒ–ä¸»ç¨‹åº
        self.llm_tts = LLMTTSTest(role_config=role_config)
        self.llm_tts.initialize_llm()

        # åˆå§‹åŒ– ASR
        self.asr = DashScopeASR(api_key=api_key, model=asr_model)
        print(f"ğŸ¤ ASR æ¨¡å‹: {asr_model}")

        # åˆå§‹åŒ– AEC å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.enable_aec = enable_aec
        self.aec_processor = None

        if enable_aec:
            # æ£€æŸ¥æ˜¯å¦æä¾›äº†è®¾å¤‡ç´¢å¼•
            if device_index is None:
                raise ValueError(
                    'å¯ç”¨ AEC æ—¶å¿…é¡»æä¾›èšåˆè®¾å¤‡ç´¢å¼•ï¼\n'
                    'è¯·å…ˆè¿è¡Œ: python voice_to_voice.py --list-devices\n'
                    'ç„¶åä½¿ç”¨: python voice_to_voice.py --device-index <ç´¢å¼•>'
                )

            try:
                self.aec_processor = SimpleAEC(sample_rate=16000)
                print("ğŸ›ï¸ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰å·²å¯ç”¨ - ä½¿ç”¨èšåˆè®¾å¤‡ + BlackHole")
            except Exception as e:
                print(f"âš ï¸ AEC åˆå§‹åŒ–å¤±è´¥: {e}")
                print("   å°†ç»§ç»­è¿è¡Œä½†ä¸ä½¿ç”¨ AEC")
                self.enable_aec = False

        # åˆå§‹åŒ–éŸ³é¢‘è¾“å…¥ï¼ˆä¼ å…¥ AEC å¤„ç†å™¨å’Œèšåˆè®¾å¤‡é…ç½®ï¼‰
        # ä½¿ç”¨ WebRTC æ ‡å‡†å¸§å¤§å°ï¼š10ms = 160 samples @ 16kHz
        self.audio_input = AudioInput(
            sample_rate=16000,
            chunk_size=160,  # ä¿®æ”¹ä¸º 10msï¼ˆWebRTC æ ‡å‡†ï¼‰
            enable_aec=self.enable_aec,
            aec_processor=self.aec_processor,
            use_aggregate_device=enable_aec,  # å¯ç”¨ AEC å°±ä½¿ç”¨èšåˆè®¾å¤‡
            device_index=device_index
        )

        # åˆå§‹åŒ–æ‰“æ–­æ§åˆ¶å™¨
        self.interrupt_controller = InterruptController()

        # åˆå§‹åŒ– TTS å®¢æˆ·ç«¯ï¼ˆå…¨å±€å¤ç”¨ï¼Œåˆå§‹åŒ–æ—¶åˆ›å»ºä¸€æ¬¡ï¼‰
        from src.tts.volcengine_realtime_tts import VolcengineRealtimeTTS
        config = self.llm_tts.config.get("volcengine_seed2", {})
        self.realtime_tts = VolcengineRealtimeTTS(
            app_id=config.get("app_id"),
            access_token=config.get("access_token") or config.get("api_key"),
            voice="zh_female_cancan_mars_bigtts"
        )

        # çŠ¶æ€
        self.is_listening = False
        self.is_tts_playing = False
        self.current_text = ""
        self.current_pipeline = None  # å½“å‰æ­£åœ¨è¿è¡Œçš„ pipeline
        self.current_player = None    # å½“å‰æ­£åœ¨æ’­æ”¾çš„ player
        self.current_tts_thread = None  # å½“å‰ TTS çº¿ç¨‹
        self.last_sentence_time = 0  # ä¸Šæ¬¡è§¦å‘å¯¹è¯çš„æ—¶é—´ï¼ˆé˜²æ­¢å¤ªå¿«é‡å¤è§¦å‘ï¼‰

    def on_asr_text(self, text: str):
        """ASR ä¸­é—´ç»“æœå›è°ƒ"""
        # å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œåªç”¨äºæ‰“æ–­æ£€æµ‹ï¼Œä¸æ˜¾ç¤º
        if self.is_tts_playing:
            self.interrupt_controller.on_asr_text(text, is_final=False)
            return

        self.current_text = text
        print(f'\rğŸ’¬ {text}', end='', flush=True)

    def on_asr_sentence(self, text: str):
        """ASR å®Œæ•´å¥å­å›è°ƒ"""
        # è¿‡æ»¤ç©ºæ–‡æœ¬å’Œå¤ªçŸ­çš„æ–‡æœ¬ï¼ˆé¿å…å™ªéŸ³è§¦å‘ï¼‰
        if not text or not text.strip() or len(text.strip()) < 2:
            return

        # å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®æ‰“æ–­
        # ä¼˜åŒ–ï¼šé™ä½é˜ˆå€¼åˆ° 4 ä¸ªå­—ç¬¦ï¼Œæé«˜æ‰“æ–­å“åº”é€Ÿåº¦
        if self.is_tts_playing:
            text_length = len(text.strip())
            # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬ï¼ˆ< 3 ä¸ªå­—ç¬¦ï¼‰å’Œå¸¸è§å›å£°è¯
            if text_length < 3:
                print(f'\nâš ï¸ å¿½ç•¥çŸ­æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å›å£°ï¼‰: "{text}" (é•¿åº¦: {text_length})')
                return

            # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªå›å£°è¯ï¼ˆ1-2 ä¸ªå­—ç¬¦çš„å¸¸è§è¯ï¼‰
            echo_keywords = ['å—¯', 'å•Š', 'å“¦', 'å‘ƒ', 'å—¯å—¯', 'å•Šå•Š', 'å“¦å“¦']
            if text.strip() in echo_keywords:
                print(f'\nâš ï¸ å¿½ç•¥å›å£°å…³é”®è¯: "{text}"')
                return

            # 3 ä¸ªå­—ç¬¦ä»¥ä¸Šçš„æ–‡æœ¬è®¤ä¸ºæ˜¯çœŸå®æ‰“æ–­
            print(f'\nğŸ”” æ£€æµ‹åˆ°æ‰“æ–­: "{text}" (é•¿åº¦: {text_length})')

        # é˜²æ­¢è¯´è¯å¤ªå¿«æ—¶é‡å¤è§¦å‘ï¼ˆé—´éš”å°‘äº1ç§’çš„å¿½ç•¥ï¼‰
        current_time = time.time()
        if current_time - self.last_sentence_time < 1.0 and not self.is_tts_playing:
            return
        self.last_sentence_time = current_time

        # å¦‚æœæ­£åœ¨æ’­æ”¾ï¼Œç›´æ¥æ‰“æ–­å¹¶æ¸…ç©ºï¼ˆä¸ç­‰å¾…ï¼‰
        if self.is_tts_playing:
            self.on_interrupt()
            # ä¸ç­‰å¾…æ—§çº¿ç¨‹ï¼Œç›´æ¥ç»§ç»­ï¼ˆæ‰“æ–­å°±æ˜¯æ‰“æ–­ï¼Œä¸ç®¡æ—§çš„äº†ï¼‰

        print(f'\n\nğŸ‘¤ ä½ : {text}')
        self.current_text = ""

        # åœæ­¢ç›‘å¬
        self.is_listening = False

        # åœ¨æ–°çº¿ç¨‹ä¸­å¤„ç† LLM + TTSï¼Œé¿å…é˜»å¡ ASR
        import threading
        tts_thread = threading.Thread(target=self._process_and_speak, args=(text,))
        tts_thread.daemon = True
        tts_thread.start()
        self.current_tts_thread = tts_thread

    def _process_and_speak(self, text: str):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¤„ç† LLM + TTS"""
        try:
            # å‘é€ç»™ LLM å¹¶æ’­æ”¾å›å¤
            self.is_tts_playing = True

            # å¯åŠ¨æ‰“æ–­ç›‘å¬ï¼ˆåœ¨ TTS æ’­æ”¾æ—¶ï¼‰
            self.interrupt_controller.set_tts_speaking(True)

            # è·å– LLM æ¶ˆæ¯
            messages = self.llm_tts.voice_prompt.get_messages(text, user_id=self.llm_tts.user_id)

            # å¤ç”¨å…¨å±€ TTS å®¢æˆ·ç«¯ï¼ˆä¸å†æ¯æ¬¡åˆ›å»ºæ–°çš„ï¼‰
            from src.audio.pyaudio_player import PyAudioStreamPlayer
            from src.realtime_pipeline import RealtimeStreamingPipeline

            # åˆ›å»ºæµå¼æ’­æ”¾å™¨ï¼ˆæ¯æ¬¡åˆ›å»ºæ–°çš„ï¼Œé¿å…çŠ¶æ€å†²çªï¼‰
            # æ³¨æ„ï¼šä½¿ç”¨èšåˆè®¾å¤‡æ—¶ï¼Œå‚è€ƒä¿¡å·é€šè¿‡ BlackHole è‡ªåŠ¨æ•è·ï¼Œæ— éœ€å›è°ƒ
            streaming_player = PyAudioStreamPlayer(
                sample_rate=24000
            )

            # åˆ›å»ºå®æ—¶ç®¡é“
            pipeline = RealtimeStreamingPipeline()

            # ä¿å­˜å¼•ç”¨ä»¥ä¾¿æ‰“æ–­
            self.current_pipeline = pipeline
            self.current_player = streaming_player

            # è·å– LLM æµå¼è¾“å‡º
            llm_stream = self.llm_tts.llm_client.chat_stream(
                messages=messages,
                temperature=self.llm_tts.test_config["llm_config"]["temperature"]
            )

            # è¿è¡Œå®æ—¶ç®¡é“ï¼ˆå¤ç”¨å…¨å±€ TTS å®¢æˆ·ç«¯ï¼‰
            result = pipeline.run(
                llm_stream=llm_stream,
                realtime_tts_client=self.realtime_tts,
                streaming_player=streaming_player,
                display_text=True
            )

            # ä¿å­˜å¯¹è¯å†å²ï¼ˆå³ä½¿è¢«æ‰“æ–­ä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸º LLM å·²ç»ç”Ÿæˆäº†å›å¤ï¼‰
            if result and result.get("text"):
                self.llm_tts.voice_prompt.add_conversation('user', text)
                self.llm_tts.voice_prompt.add_conversation('assistant', result["text"])

                # ä¿å­˜åˆ° Mem0ï¼ˆå³ä½¿è¢«æ‰“æ–­ä¹Ÿè¦ä¿å­˜ï¼Œå› ä¸ºå¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
                if self.llm_tts.mem0_manager:
                    self.llm_tts.mem0_manager.add_conversation(
                        user_input=text,
                        assistant_response=result["text"],
                        user_id=self.llm_tts.user_id
                    )

        except Exception as e:
            print(f'\nâŒ é”™è¯¯: {e}')

        finally:
            # æ¸…é™¤å¼•ç”¨
            self.current_pipeline = None
            self.current_player = None

            # TTS æ’­æ”¾å®Œæˆ
            self.is_tts_playing = False
            self.interrupt_controller.set_tts_speaking(False)

            # é‡æ–°å¼€å§‹ç›‘å¬
            self.is_listening = True
            print('\n')

    def on_interrupt(self):
        """æ‰“æ–­å›è°ƒ"""
        # åœæ­¢ TTS ç®¡é“
        if self.current_pipeline:
            self.current_pipeline.stop()

        # ç«‹å³ç»“æŸæ—§ sessionï¼ˆç«å±±å¼•æ“é™åˆ¶åŒæ—¶åªèƒ½æœ‰1ä¸ªsessionï¼‰
        if hasattr(self, 'realtime_tts'):
            self.realtime_tts.finish()
            self.realtime_tts.clear_queue()

        # åœæ­¢éŸ³é¢‘æ’­æ”¾
        if self.current_player:
            self.current_player.stop()

        self.is_tts_playing = False

    def start(self):
        """å¯åŠ¨è¯­éŸ³äº¤äº’"""
        print('\nğŸ™ï¸  å¯¼å¸ˆè¯„ä»·å­¦å§åŠ©æ‰‹ - è¯­éŸ³äº¤äº’æ¨¡å¼')
        if self.enable_aec:
            print('ğŸ›ï¸  AEC å›å£°æ¶ˆé™¤å·²å¯ç”¨')
        print('â”' * 50)
        print('æŒ‰ Ctrl+C é€€å‡º\n')

        try:
            # å¯åŠ¨éŸ³é¢‘è¾“å…¥ï¼ˆå…ˆå¯åŠ¨ï¼Œç¡®ä¿éº¦å…‹é£æ‰“å¼€ï¼‰
            self.audio_input.start(audio_callback=self.asr.send_audio)

            # å¯åŠ¨ ASRï¼ˆåœ¨åå°ï¼‰
            import threading
            asr_thread = threading.Thread(
                target=self.asr.start,
                kwargs={
                    'on_text': self.on_asr_text,
                    'on_sentence': self.on_asr_sentence
                },
                daemon=True
            )
            asr_thread.start()
            time.sleep(0.5)

            # å¯åŠ¨æ‰“æ–­æ§åˆ¶å™¨
            self.interrupt_controller.start_monitoring(
                interrupt_callback=self.on_interrupt
            )

            self.is_listening = True
            print('ğŸ¤ è¯·è¯´è¯...\n')

            # æŒç»­è¿è¡Œ
            while True:
                time.sleep(0.1)

        except KeyboardInterrupt:
            print('\n\nğŸ‘‹ å†è§!')

        finally:
            # æ¸…ç†èµ„æº
            self.audio_input.stop()
            self.asr.stop()
            self.audio_input.close()
            self.interrupt_controller.stop_monitoring()

            # å…³é—­ AEC å¤„ç†å™¨
            if self.aec_processor:
                self.aec_processor.close()

            # æ–­å¼€ TTS è¿æ¥ï¼ˆå¤ç”¨çš„å…¨å±€å®¢æˆ·ç«¯ï¼‰
            if hasattr(self, 'realtime_tts'):
                self.realtime_tts.disconnect()


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='è¯­éŸ³äº¤äº’æ¨¡å¼ - æ”¯æŒ AEC å›å£°æ¶ˆé™¤ï¼ˆéœ€è¦èšåˆè®¾å¤‡ + BlackHoleï¼‰')
    parser.add_argument('--no-aec', action='store_true', help='ç¦ç”¨ AECï¼ˆå›å£°æ¶ˆé™¤ï¼‰ï¼Œä½¿ç”¨è€³æœºæ¨¡å¼')
    parser.add_argument('--device-index', type=int, help='èšåˆè®¾å¤‡ç´¢å¼•ï¼ˆå¯ç”¨ AEC æ—¶å¿…é¡»æä¾›ï¼‰')
    parser.add_argument('--asr-model', type=str, default='paraformer-realtime-v2',
                        choices=['paraformer-realtime-v2', 'fun-asr-realtime-2025-11-07'],
                        help='ASR æ¨¡å‹é€‰æ‹©ï¼ˆé»˜è®¤: paraformer-realtime-v2ï¼‰')
    parser.add_argument('--list-devices', action='store_true', help='åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡')
    args = parser.parse_args()

    # å¦‚æœç”¨æˆ·è¦æ±‚åˆ—å‡ºè®¾å¤‡
    if args.list_devices:
        import pyaudio
        p = pyaudio.PyAudio()
        print("\nå¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼š")
        print("=" * 80)
        for i in range(p.get_device_count()):
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                print(f"\nè®¾å¤‡ {i}: {info['name']}")
                print(f"  è¾“å…¥é€šé“æ•°: {info['maxInputChannels']}")
                print(f"  é‡‡æ ·ç‡: {int(info['defaultSampleRate'])} Hz")
                if 'Aggregate' in info['name'] or 'aggregate' in info['name'].lower():
                    print("  â­ è¿™æ˜¯èšåˆè®¾å¤‡ï¼")
        print("=" * 80)
        print("\nä½¿ç”¨æ–¹æ³•ï¼š")
        print("  1. ç¦ç”¨ AECï¼ˆè€³æœºæ¨¡å¼ï¼‰ï¼špython voice_to_voice.py --no-aec")
        print("  2. å¯ç”¨ AECï¼ˆå¤–æ”¾æ¨¡å¼ï¼‰ï¼špython voice_to_voice.py --device-index <èšåˆè®¾å¤‡ç´¢å¼•>")
        p.terminate()
        return

    try:
        voice_mode = VoiceInteractiveMode(
            enable_aec=not args.no_aec,
            device_index=args.device_index,
            asr_model=args.asr_model
        )
        voice_mode.start()
    except Exception as e:
        print(f'é”™è¯¯: {e}')
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
