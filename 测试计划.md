# LLM + TTS API 对话语音与文字匹配度测试计划

## 项目概述
本项目旨在测试不同平台的大语言模型（LLM）API 和文本转语音（TTS）API 的组合效果，评估生成的语音与文字内容的匹配度、自然度和表现力。

## 测试目标
1. 评估不同 LLM 生成的对话文本质量
2. 评估不同 TTS 将文本转换为语音的质量
3. 分析不同提示词对结果的影响
4. 找出最佳的 LLM + TTS 组合方案

## 测试平台

### LLM API 平台
- **OpenAI**
  - GPT-4
  - GPT-3.5-turbo
- **Anthropic**
  - Claude 3.5 Sonnet
  - Claude 3 Opus
- **Google**
  - Gemini Pro
- **国内平台**
  - 文心一言（百度）
  - 通义千问（阿里）
  - 智谱 GLM-4

### TTS API 平台
- **OpenAI TTS**
  - tts-1
  - tts-1-hd
- **Azure Speech Services**
  - 多种语音选项
- **Google Cloud Text-to-Speech**
- **Amazon Polly**
- **国内平台**
  - 阿里云语音合成
  - 腾讯云语音合成
  - 讯飞语音合成

## 测试场景设计

### 场景 1：日常对话
- 闲聊场景
- 问候与告别
- 天气、美食等轻松话题

### 场景 2：情感表达
- 开心、兴奋的情绪
- 悲伤、失落的情绪
- 愤怒、不满的情绪
- 惊讶、疑惑的情绪

### 场景 3：专业内容
- 技术讲解
- 新闻播报
- 教学内容
- 商务对话

### 场景 4：故事叙述
- 儿童故事
- 悬疑故事
- 情感故事

## 提示词设计

### 基础提示词模板
```
你是一个{角色}，请用{语气}的方式回答以下问题：{问题内容}
要求：
- 回答长度：{短/中/长}
- 语言风格：{正式/随意/幽默/专业}
- 情感色彩：{中性/积极/消极}
```

### 提示词变量组合
1. **角色类型**
   - 友好的助手
   - 专业的顾问
   - 热情的主播
   - 温柔的讲述者

2. **语气风格**
   - 平静客观
   - 热情洋溢
   - 温柔体贴
   - 严肃认真
   - 幽默风趣

3. **回答长度**
   - 短（1-2句）
   - 中（3-5句）
   - 长（6-10句）

## 评估维度

### 1. 文本质量评估（LLM 输出）
- **内容准确性**（1-5分）：回答是否准确、相关
- **语言流畅度**（1-5分）：表达是否自然、通顺
- **情感适配度**（1-5分）：情感表达是否符合场景
- **创意性**（1-5分）：回答是否有趣、有新意

### 2. 语音质量评估（TTS 输出）
- **发音准确性**（1-5分）：字词发音是否正确
- **语音自然度**（1-5分）：是否接近真人说话
- **韵律节奏**（1-5分）：停顿、语速是否合理
- **情感表现力**（1-5分）：语音是否传达了文本情感

### 3. 匹配度评估（整体）
- **文字-语音一致性**（1-5分）：语音是否准确表达文字含义
- **情感传递效果**（1-5分）：情感是否通过语音有效传递
- **整体体验**（1-5分）：听众的整体感受

## 测试流程

### 阶段 1：环境准备
1. 注册并获取各平台 API 密钥
2. 搭建测试环境（Python/Node.js）
3. 准备测试数据集（问题列表）
4. 设计评分表格

### 阶段 2：数据收集
1. 使用相同提示词调用不同 LLM API
2. 收集所有 LLM 的文本输出
3. 将每个文本输入到不同 TTS API
4. 保存所有生成的音频文件
5. 记录 API 响应时间和成本

### 阶段 3：评估测试
1. 组织评估小组（3-5人）
2. 盲测评分（不告知使用的平台）
3. 记录每个维度的评分
4. 收集主观反馈意见

### 阶段 4：数据分析
1. 统计各平台的平均得分
2. 分析不同场景下的表现差异
3. 计算性价比（质量/成本）
4. 生成可视化报告

## 技术实现方案

### 项目结构
```
llm-tts-api-test/
├── config/
│   ├── api_keys.json          # API 密钥配置
│   └── test_config.json       # 测试配置
├── prompts/
│   ├── daily_conversation.json    # 日常对话提示词
│   ├── emotional_expression.json  # 情感表达提示词
│   ├── professional_content.json  # 专业内容提示词
│   └── storytelling.json          # 故事叙述提示词
├── src/
│   ├── llm_client.py          # LLM API 调用封装
│   ├── tts_client.py          # TTS API 调用封装
│   ├── test_runner.py         # 测试执行器
│   └── evaluator.py           # 评估工具
├── data/
│   ├── test_cases.json        # 测试用例
│   └── results/               # 测试结果
│       ├── texts/             # LLM 生成的文本
│       └── audios/            # TTS 生成的音频
├── evaluation/
│   ├── scoring_sheet.xlsx     # 评分表
│   └── analysis.ipynb         # 数据分析笔记本
├── reports/
│   └── final_report.md        # 最终测试报告
├── requirements.txt           # Python 依赖
└── README.md                  # 项目说明
```

### 核心代码模块

#### 1. LLM Client 封装
```python
class LLMClient:
    def __init__(self, platform, api_key, model):
        pass

    def generate_text(self, prompt, temperature=0.7):
        # 调用对应平台 API
        pass
```

#### 2. TTS Client 封装
```python
class TTSClient:
    def __init__(self, platform, api_key, voice):
        pass

    def text_to_speech(self, text, output_path):
        # 调用对应平台 API
        pass
```

#### 3. 测试执行器
```python
class TestRunner:
    def run_test(self, test_case, llm_platforms, tts_platforms):
        # 执行完整测试流程
        pass
```

## 测试用例示例

### 用例 1：日常问候
```json
{
  "id": "daily_001",
  "scenario": "日常对话",
  "prompt_template": "你是一个友好的助手，请用热情的方式回答：早上好！今天天气怎么样？",
  "expected_emotion": "积极、热情",
  "expected_length": "中"
}
```

### 用例 2：情感安慰
```json
{
  "id": "emotion_001",
  "scenario": "情感表达",
  "prompt_template": "你是一个温柔体贴的朋友，请用关心的语气回答：我今天工作遇到了很多困难，感觉很沮丧。",
  "expected_emotion": "温柔、关心、安慰",
  "expected_length": "长"
}
```

## 成本预估

### API 调用成本
- LLM API：根据 token 数量计费
  - 预估每次调用：$0.001 - $0.05
- TTS API：根据字符数量计费
  - 预估每次调用：$0.001 - $0.02

### 测试规模
- 测试场景：4 个
- 每场景用例：10 个
- LLM 平台：6 个
- TTS 平台：6 个
- 总调用次数：40 × 6 × 6 = 1440 次
- 预估总成本：$50 - $200

## 时间安排

1. **环境准备**：准备 API 密钥和开发环境
2. **代码开发**：实现 API 调用和测试框架
3. **数据收集**：执行测试并收集结果
4. **评估分析**：组织评分和数据分析
5. **报告撰写**：整理结果并生成报告

## 预期输出

### 1. 量化数据
- 各平台各维度评分表
- 不同场景下的表现对比
- 性价比分析

### 2. 音频样本库
- 分类整理的音频文件
- 最佳/最差案例集合

### 3. 最终报告
- 测试方法说明
- 详细数据分析
- 平台推荐建议
- 最佳实践总结

## 注意事项

1. **API 限流**：注意各平台的速率限制，避免被封禁
2. **成本控制**：监控 API 调用成本，设置预算上限
3. **数据安全**：妥善保管 API 密钥，不要上传到公开仓库
4. **版权问题**：生成的音频仅用于测试，注意使用条款
5. **评估客观性**：采用盲测方式，避免主观偏见
6. **结果可重复性**：记录所有参数，确保测试可重现

## 扩展方向

1. **多语言测试**：扩展到英语、日语等其他语言
2. **实时对话**：测试流式 API 的实时对话效果
3. **个性化语音**：测试语音克隆和定制化功能
4. **多模态评估**：结合视觉元素（如虚拟形象）评估
5. **用户调研**：扩大评估样本，进行大规模用户调研
