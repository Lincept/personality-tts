"""
ä¸»æµ‹è¯•è„šæœ¬ - LLM + TTS é›†æˆæµ‹è¯•
æ”¯æŒå®æ—¶æµå¼å¯¹è¯å’Œå®æ—¶è¯­éŸ³æ’­æ”¾
é‡‡ç”¨ä¸¤é˜¶æ®µç»“æ„åŒ–è¾“å‡ºè®°å¿†ç®¡ç†æ–¹æ¡ˆ
"""
import os
import sys
import json
import logging

from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm.llm_client import LLMClient
from src.tts.qwen3_realtime_tts import Qwen3RealtimeTTS
from src.tts.volcengine_realtime_tts import VolcengineRealtimeTTS
from src.audio.pyaudio_player import PyAudioStreamPlayer
from src.config_loader import ConfigLoader
from src.realtime_pipeline import RealtimeStreamingPipeline
from src.voice_assistant_prompt import VoiceAssistantPrompt
from src.role_loader import RoleLoader
from src.memory.mem0_manager import Mem0Manager
from src.memory.memory_chat import MemoryEnhancedChat

def _parse_log_level(value: str) -> int | None:
    """Parse log level from env; return None for 'OFF' (disable logging)."""
    if value is None:
        return logging.INFO
    v = str(value).strip().upper()
    if v in {"OFF", "NONE", "DISABLE", "FALSE", "0"}:
        return None
    if v.isdigit():
        return int(v)
    return getattr(logging, v, logging.INFO)


# å°½æ—©åŠ è½½ .envï¼Œä¿è¯ import é˜¶æ®µå°±èƒ½æŒ‰ç¯å¢ƒå˜é‡æ§åˆ¶æ—¥å¿—
load_dotenv()

_level = _parse_log_level(os.getenv("PTTS_LOG_LEVEL"))
if _level is None:
    logging.disable(logging.CRITICAL)
else:
    # force=True ç¡®ä¿å³ä½¿å…¶å®ƒæ¨¡å—å·²é…ç½®è¿‡ handler ä¹Ÿèƒ½æŒ‰ç¯å¢ƒå˜é‡é‡æ–°é…ç½®
    logging.basicConfig(level=_level, force=True)
    root_logger = logging.getLogger()
    for h in root_logger.handlers:
        h.setLevel(_level)

    # å¸¸è§å™ªå£°æ¥æºï¼šHTTP å®¢æˆ·ç«¯ã€WebSocketã€ä»¥åŠæœ¬é¡¹ç›®çš„ memory_chat
    for name in ("httpx", "httpcore", "websocket", "websockets", "memory_chat"):
        logging.getLogger(name).setLevel(_level)


class LLMTTSTest:
    def __init__(self, config_path: str = "config/api_keys.json", role_config: dict = None, role_loader: RoleLoader = None):
        """
        åˆå§‹åŒ–æµ‹è¯•ç±»

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            role_config: è§’è‰²é…ç½®ï¼ˆä» role_loader åŠ è½½ï¼‰
            role_loader: è§’è‰²åŠ è½½å™¨å®ä¾‹
        """
        self.role_loader = role_loader
        # ä½¿ç”¨æ–°çš„é…ç½®åŠ è½½å™¨
        config_loader = ConfigLoader()
        self.config = config_loader.get_config()

        # é™é»˜æ‰“å°é…ç½®çŠ¶æ€
        # config_loader.print_status()

        self.test_config = self._load_test_config()
        self.llm_client = None
        self.output_dir = self.test_config.get("output_dir", "data/audios")

        # åˆå§‹åŒ– Mem0 è®°å¿†ç®¡ç†å™¨
        mem0_config = self.config.get("mem0", {})
        self.mem0_manager = None
        if mem0_config.get("enable_mem0", False):
            self.mem0_manager = Mem0Manager(mem0_config)

        # ç”¨æˆ·IDï¼ˆä»é…ç½®è·å–ï¼‰
        self.user_id = mem0_config.get("user_id", "default_user")

        # è§’è‰²æè¿°ï¼ˆç”¨äºè®°å¿†å¢å¼ºå¯¹è¯ï¼‰
        self.role_description = "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¯´è¯ç®€æ´è‡ªç„¶"
        if role_config:
            self.role_description = f"ä½ æ˜¯{role_config.get('name', 'åŠ©æ‰‹')}ï¼Œ{role_config.get('personality', 'å‹å¥½')}"

        # åˆå§‹åŒ–è®°å¿†å¢å¼ºå¯¹è¯ï¼ˆæ–°æ–¹æ¡ˆï¼šä¸¤é˜¶æ®µç»“æ„åŒ–è¾“å‡ºï¼‰
        llm_config = self.config.get("openai_compatible", {})
        self.memory_chat = MemoryEnhancedChat(
            api_key=llm_config.get("api_key"),
            base_url=llm_config.get("base_url"),
            model=llm_config.get("model", "qwen3-max"),
            mem0_manager=self.mem0_manager,
            user_id=self.user_id,
            role_description=self.role_description,
            verbose=False  # ç”Ÿäº§æ¨¡å¼å…³é—­è¯¦ç»†æ—¥å¿—
        )

        # åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹ Prompt ç®¡ç†å™¨ï¼ˆä¿ç•™ç”¨äºå¯¹è¯å†å²ç®¡ç†ï¼‰
        self.voice_prompt = VoiceAssistantPrompt(role_config=role_config, mem0_manager=None, role_loader=role_loader)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)

    def _load_test_config(self) -> dict:
        """åŠ è½½æµ‹è¯•é…ç½®"""
        with open("config/test_config.json", 'r', encoding='utf-8') as f:
            return json.load(f)

    def initialize_llm(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        llm_config = self.config.get("openai_compatible", {})
        self.llm_client = LLMClient(
            api_key=llm_config.get("api_key"),
            base_url=llm_config.get("base_url"),
            model=llm_config.get("model")
        )
        # print(f"âœ“ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ: {self.llm_client.get_model_info()}")  # é™é»˜åˆå§‹åŒ–

    def chat_and_speak_realtime(self, prompt: str, play_audio: bool = True):
        """
        çœŸæ­£çš„å®æ—¶å¯¹è¯ï¼ˆä¸¤é˜¶æ®µç»“æ„åŒ–è¾“å‡ºè®°å¿†æ–¹æ¡ˆï¼‰
        ç¬¬ä¸€é˜¶æ®µï¼šåˆ†ææ„å›¾ï¼Œæ£€ç´¢/å­˜å‚¨è®°å¿†
        ç¬¬äºŒé˜¶æ®µï¼šæµå¼ç”Ÿæˆå›å¤ â†’ å®æ—¶ TTS â†’ æµå¼æ’­æ”¾

        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            play_audio: æ˜¯å¦æ’­æ”¾éŸ³é¢‘
        """
        # è·å–å¯¹è¯å†å²
        history = []
        for msg in self.voice_prompt.conversation_history:
            history.append(msg)

        # åˆ›å»ºå®æ—¶ TTS å®¢æˆ·ç«¯
        config = self.config.get("qwen3_tts", {})
        realtime_tts = Qwen3RealtimeTTS(
            api_key=config.get("api_key"),
            voice="Cherry",
            verbose=False  # å…³é—­ TTS æ—¥å¿—
        )

        # åˆ›å»ºæµå¼æ’­æ”¾å™¨ - PyAudio
        streaming_player = PyAudioStreamPlayer(sample_rate=24000)

        # åˆ›å»ºå®æ—¶ç®¡é“
        pipeline = RealtimeStreamingPipeline()

        # ä½¿ç”¨ MemoryEnhancedChat çš„æµå¼è¾“å‡ºï¼ˆä¸¤é˜¶æ®µè®°å¿†ç®¡ç†ï¼‰
        def llm_stream_generator():
            """å°† MemoryEnhancedChat.chat_stream è½¬æ¢ä¸º pipeline éœ€è¦çš„æ ¼å¼"""
            for chunk in self.memory_chat.chat_stream(prompt, history):
                yield chunk

        # è¿è¡Œå®æ—¶ç®¡é“
        result = pipeline.run(
            llm_stream=llm_stream_generator(),
            realtime_tts_client=realtime_tts,
            streaming_player=streaming_player,
            display_text=True
        )

        # ä¿å­˜å¯¹è¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
        self.voice_prompt.add_conversation('user', prompt)
        self.voice_prompt.add_conversation('assistant', result["text"])

        print()  # æ¢è¡Œ

        return {
            "prompt": prompt,
            "response": result["text"],
            "mode": "realtime",
            "metrics": result["metrics"]
        }

    def chat_and_speak_realtime_volcengine(self, prompt: str, play_audio: bool = True):
        """
        ç«å±±å¼•æ“å®æ—¶å¯¹è¯ï¼ˆä¸¤é˜¶æ®µç»“æ„åŒ–è¾“å‡ºè®°å¿†æ–¹æ¡ˆï¼‰
        ç¬¬ä¸€é˜¶æ®µï¼šåˆ†ææ„å›¾ï¼Œæ£€ç´¢/å­˜å‚¨è®°å¿†
        ç¬¬äºŒé˜¶æ®µï¼šæµå¼ç”Ÿæˆå›å¤ â†’ å®æ—¶ TTS â†’ æµå¼æ’­æ”¾

        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            play_audio: æ˜¯å¦æ’­æ”¾éŸ³é¢‘
        """
        # è·å–å¯¹è¯å†å²
        history = []
        for msg in self.voice_prompt.conversation_history:
            history.append(msg)

        # åˆ›å»ºå®æ—¶ TTS å®¢æˆ·ç«¯
        config = self.config.get("volcengine_seed2", {})
        realtime_tts = VolcengineRealtimeTTS(
            app_id=config.get("app_id"),
            access_token=config.get("access_token") or config.get("api_key"),
            voice="zh_female_cancan_mars_bigtts"
        )

        # åˆ›å»ºæµå¼æ’­æ”¾å™¨ - PyAudio
        streaming_player = PyAudioStreamPlayer(sample_rate=24000)

        # åˆ›å»ºå®æ—¶ç®¡é“
        pipeline = RealtimeStreamingPipeline()

        # ä½¿ç”¨ MemoryEnhancedChat çš„æµå¼è¾“å‡ºï¼ˆä¸¤é˜¶æ®µè®°å¿†ç®¡ç†ï¼‰
        def llm_stream_generator():
            """å°† MemoryEnhancedChat.chat_stream è½¬æ¢ä¸º pipeline éœ€è¦çš„æ ¼å¼"""
            for chunk in self.memory_chat.chat_stream(prompt, history):
                yield chunk

        # è¿è¡Œå®æ—¶ç®¡é“
        result = pipeline.run(
            llm_stream=llm_stream_generator(),
            realtime_tts_client=realtime_tts,
            streaming_player=streaming_player,
            display_text=True
        )

        # ä¿å­˜å¯¹è¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
        self.voice_prompt.add_conversation('user', prompt)
        self.voice_prompt.add_conversation('assistant', result["text"])

        print()  # æ¢è¡Œ

        return {
            "prompt": prompt,
            "response": result["text"],
            "mode": "realtime_volcengine",
            "metrics": result["metrics"]
        }

    def interactive_mode(self, use_realtime: bool = True):
        """
        äº¤äº’å¼å¯¹è¯æ¨¡å¼

        Args:
            use_realtime: æ˜¯å¦ä½¿ç”¨å®æ—¶æ¨¡å¼ï¼ˆé»˜è®¤å¼€å¯ï¼‰
        """
        print("\n" + "="*60)
        print("ğŸ™ï¸  è¯­éŸ³åŠ©æ‰‹äº¤äº’æ¨¡å¼")
        print("="*60)
        print("\nå‘½ä»¤:")
        print("  /quit      - é€€å‡º")
        print("  /provider  - åˆ‡æ¢ TTS æä¾›å•†")
        print("  /role      - åˆ‡æ¢è§’è‰²")
        print("  /clear     - æ¸…ç©ºå¯¹è¯å†å²")
        print("  /memories  - æŸ¥çœ‹é•¿æœŸè®°å¿†")
        print("  /clearmem  - æ¸…é™¤é•¿æœŸè®°å¿†")
        print("  /user <ID> - åˆ‡æ¢ç”¨æˆ·")
        print()

        current_provider = "qwen3"

        provider_desc = {
            "qwen3": "é€šä¹‰åƒé—® TTS",
            "volcengine": "ç«å±±å¼•æ“ TTS"
        }

        print(f"å½“å‰ TTS: {provider_desc[current_provider]}")
        if self.mem0_manager and self.mem0_manager.enabled:
            print(f"è®°å¿†åŠŸèƒ½: âœ… å·²å¯ç”¨ (ç”¨æˆ·: {self.user_id})")
        else:
            print(f"è®°å¿†åŠŸèƒ½: âŒ æœªå¯ç”¨")
        print()

        while True:
            try:
                user_input = input("ğŸ’¬ ä½ : ").strip()

                if not user_input:
                    continue

                if user_input == "/quit":
                    print("\nğŸ‘‹ å†è§!")
                    break

                elif user_input == "/help":
                    print("\nğŸ“– å¯ç”¨å‘½ä»¤:")
                    print("  /quit      - é€€å‡ºç¨‹åº")
                    print("  /provider  - åˆ‡æ¢ TTS æä¾›å•† (qwen3/volcengine)")
                    print("  /role      - åˆ‡æ¢è§’è‰²")
                    print("  /clear     - æ¸…ç©ºå¯¹è¯å†å²")
                    print("  /history   - æŸ¥çœ‹å¯¹è¯å†å²")
                    print("  /memories  - æŸ¥çœ‹é•¿æœŸè®°å¿†")
                    print("  /clearmem  - æ¸…é™¤é•¿æœŸè®°å¿†")
                    print("  /user <ID> - åˆ‡æ¢ç”¨æˆ·")
                    print("  /info      - æŸ¥çœ‹å½“å‰é…ç½®")
                    print("  /help      - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
                    print()

                elif user_input == "/provider":
                    # å¾ªç¯åˆ‡æ¢ TTS æä¾›å•†
                    providers = ["qwen3", "volcengine"]
                    current_idx = providers.index(current_provider)
                    current_provider = providers[(current_idx + 1) % len(providers)]
                    print(f"âœ“ å·²åˆ‡æ¢åˆ°: {provider_desc[current_provider]}\n")

                elif user_input == "/clear":
                    self.voice_prompt.clear_history()
                    print("âœ“ å¯¹è¯å†å²å·²æ¸…ç©º\n")

                elif user_input.startswith("/role"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) > 1:
                        role = parts[1]
                        try:
                            self.voice_prompt.set_role(role)
                            role_info = self.voice_prompt.get_role_info()
                            print(f"âœ“ å·²åˆ‡æ¢åˆ°è§’è‰²: {role_info['name']}\n")
                        except ValueError as e:
                            print(f"âŒ {str(e)}\n")
                    else:
                        current_role = self.voice_prompt.get_role_info()
                        print(f"å½“å‰è§’è‰²: {current_role['name']}")
                        if self.role_loader:
                            role_ids = ", ".join(self.role_loader.get_role_ids())
                            print(f"å¯é€‰è§’è‰²: {role_ids}\n")
                        else:
                            print("å¯é€‰è§’è‰²: æœªåŠ è½½è§’è‰²åˆ—è¡¨\n")

                elif user_input == "/history":
                    summary = self.voice_prompt.get_conversation_summary()
                    print(f"\nå¯¹è¯å†å²:\n{summary}\n")

                elif user_input.startswith("/setname"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) > 1:
                        name = parts[1]
                        self.voice_prompt.set_user_info(name=name)
                        print(f"âœ“ ç”¨æˆ·åå·²è®¾ç½®ä¸º: {name}\n")
                    else:
                        print("âŒ è¯·æä¾›ç”¨æˆ·åï¼Œä¾‹å¦‚: /setname å°æ˜\n")

                elif user_input.startswith("/addknowledge"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) > 1:
                        knowledge = parts[1]
                        self.voice_prompt.add_knowledge(knowledge)
                        print(f"âœ“ å·²æ·»åŠ çŸ¥è¯†: {knowledge}\n")
                    else:
                        print("âŒ è¯·æä¾›çŸ¥è¯†å†…å®¹ï¼Œä¾‹å¦‚: /addknowledge ç”¨æˆ·å–œæ¬¢æ”€å²©\n")

                elif user_input == "/memories":
                    # æŸ¥çœ‹é•¿æœŸè®°å¿†
                    if self.mem0_manager and self.mem0_manager.enabled:
                        memories = self.mem0_manager.get_all_memories(self.user_id)
                        if memories:
                            print(f"\nğŸ“ é•¿æœŸè®°å¿† (ç”¨æˆ·: {self.user_id}):")
                            for i, mem in enumerate(memories, 1):
                                print(f"  {i}. {mem['memory']}")
                            print()
                        else:
                            print("æš‚æ— é•¿æœŸè®°å¿†\n")
                    else:
                        print("âŒ Mem0 æœªå¯ç”¨\n")

                elif user_input == "/clearmem":
                    # æ¸…é™¤é•¿æœŸè®°å¿†
                    if self.mem0_manager and self.mem0_manager.enabled:
                        self.mem0_manager.clear_memories(self.user_id)
                        print(f"âœ“ å·²æ¸…é™¤ç”¨æˆ· {self.user_id} çš„æ‰€æœ‰è®°å¿†\n")
                    else:
                        print("âŒ Mem0 æœªå¯ç”¨\n")

                elif user_input.startswith("/user"):
                    # åˆ‡æ¢ç”¨æˆ·
                    parts = user_input.split(maxsplit=1)
                    if len(parts) > 1:
                        self.user_id = parts[1]
                        # æ›´æ–° memory_chat çš„ user_id
                        self.memory_chat.user_id = self.user_id
                        print(f"âœ“ å·²åˆ‡æ¢åˆ°ç”¨æˆ·: {self.user_id}\n")
                    else:
                        print(f"å½“å‰ç”¨æˆ·: {self.user_id}\n")

                elif user_input == "/info":
                    role_info = self.voice_prompt.get_role_info()
                    print("\nå½“å‰é…ç½®:")
                    print(f"  TTS æä¾›å•†: {provider_desc[current_provider]}")
                    print(f"  è§’è‰²: {role_info['name']} ({role_info['personality']})")
                    print(f"  å¯¹è¯è½®æ•°: {len(self.voice_prompt.conversation_history) // 2}")
                    print(f"  çŸ¥è¯†åº“æ¡ç›®: {len(self.voice_prompt.knowledge_base)}")
                    if self.mem0_manager and self.mem0_manager.enabled:
                        mem_count = len(self.mem0_manager.get_all_memories(self.user_id))
                        print(f"  é•¿æœŸè®°å¿†: {mem_count} æ¡ (ç”¨æˆ·: {self.user_id})")
                    print()

                else:
                    # å®æ—¶å¯¹è¯
                    if current_provider == "qwen3":
                        self.chat_and_speak_realtime(user_input)
                    elif current_provider == "volcengine":
                        self.chat_and_speak_realtime_volcengine(user_input)

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§!")
                # ç¡®ä¿æ­£ç¡®å…³é—­ Mem0 è¿æ¥
                if self.mem0_manager and self.mem0_manager.enabled:
                    self.mem0_manager.close()
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {str(e)}\n")

        # æ­£å¸¸é€€å‡ºæ—¶ä¹Ÿè¦å…³é—­è¿æ¥
        if self.mem0_manager and self.mem0_manager.enabled:
            self.mem0_manager.close()


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½è§’è‰²
    print("\næ­£åœ¨åŠ è½½è§’è‰²...")
    role_loader = RoleLoader()

    # è®©ç”¨æˆ·é€‰æ‹©è§’è‰²
    selected_role_id = role_loader.select_role_interactive()

    # è·å–è§’è‰²é…ç½®
    role_config = None
    if selected_role_id:
        role_config = role_loader.get_role(selected_role_id)
        print(f"\nâœ“ ä½¿ç”¨è§’è‰²: {role_config['name']}")
        print(f"  ç‰¹ç‚¹: {role_config['personality']}")
        print(f"  é£æ ¼: {role_config['style']}\n")

    # åˆå§‹åŒ–æµ‹è¯•ç±»ï¼ˆä¼ å…¥è§’è‰²é…ç½®å’Œè§’è‰²åŠ è½½å™¨ï¼‰
    test = LLMTTSTest(role_config=role_config, role_loader=role_loader)

    # é»˜è®¤è¿›å…¥äº¤äº’æ¨¡å¼
    test.interactive_mode()


if __name__ == "__main__":
    main()
